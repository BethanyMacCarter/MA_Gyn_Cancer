{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0d5adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc742d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set max columns, rows, column width in pandas so doesn't truncate\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth',250) # or -1\n",
    "pd.set_option('display.max_columns', None) # or 500\n",
    "pd.set_option('display.max_rows', None) # or 500\n",
    "\n",
    "# sets the cell width to 100% respective to the screen size\n",
    "from IPython.core.display import display, HTML\n",
    "from pyspark.sql.functions import when, col\n",
    "from pyspark.sql.functions import avg\n",
    "display(HTML(\"<style>.container { width:92% !important; }</style>\"))\n",
    "from pyspark.sql.functions import col, sum as spark_sum\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.functions import col, monotonically_increasing_id\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import numpy as np\n",
    "from pyspark.sql.functions import col, log\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f61c8a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "99121b53",
   "metadata": {},
   "source": [
    "### Call in data and obtain caliper radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d3452f",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql('use CUA_db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8b9240",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Call in saved dataframe with propensity scores\n",
    "cua_non= spark.sql(\"\"\"\n",
    "    SELECT personid, CUA_ANY, prob1 AS prob\n",
    "    FROM cua_non_age_PSM_update\n",
    "\"\"\")\n",
    "cua_non"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfcefb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate and use logit of PS for estimating the caliper width in KNN matching\n",
    "cua_non_logit = cua_non.withColumn('logit_prob', log(col('prob') / (1 - col('prob'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369f26d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_std_dev = cua_non_logit.agg(F.stddev('logit_prob')).collect()[0][0]\n",
    "\n",
    "# Set the caliper radius to be 0.2 times the standard deviation of the logit\n",
    "caliper_radius = 0.2 * logit_std_dev\n",
    "\n",
    "print(\"Caliper Radius from all data:\",caliper_radius)\n",
    "#Caliper Radius from all data: 0.1274663032446158"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f3eb38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bc25b74b",
   "metadata": {},
   "source": [
    "### Filter Control and treatment groups by PS stratifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea29b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separate groups to chunk by PS distributions (Controls are much larger and need randomization)\n",
    "\n",
    "filter_CUA = cua_non_logit.filter(cua_non_logit['CUA_ANY'] == 1)  # Filter treatment group\n",
    "filter_non=cua_non_logit.filter(cua_non_logit['CUA_ANY'] == 0)  # Filter control group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845daf06",
   "metadata": {},
   "outputs": [],
   "source": [
    "CUA_count=filter_CUA.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f93e201",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_count=filter_non.count()\n",
    "non_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3381cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "highest_prob_cua=filter_CUA.filter(col('prob') > 0.79)\n",
    "highest_cua_count=highest_prob_cua.count()\n",
    "print(\"percent of highest prob CUA:\"); (highest_cua_count/CUA_count *100)\n",
    "\n",
    "#percent of highest prob CUA: 10.596584920244537\n",
    "\n",
    "print(highest_cua_count)\n",
    "##3016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdaba2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "highest_prob_non = filter_non.filter(col('prob') > 0.79)\n",
    "highest_non_count=highest_prob_non.count()\n",
    "print(\"percent of highest prob non:\"); (highest_non_count/non_count *100)\n",
    "\n",
    "#percent of highest prob non:  0.6931692983749175"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4518c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_highest_prob=highest_prob_non.union(highest_prob_cua)\n",
    "concat_highest_pdf=concat_highest_prob.toPandas()\n",
    "print(concat_highest_pdf.count())\n",
    "print(concat_highest_pdf.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0336df88",
   "metadata": {},
   "outputs": [],
   "source": [
    "high_prob_cua = filter_CUA.filter((col('prob') > 0.74) & (col('prob') < 0.79))\n",
    "high_prob_cua_count=high_prob_cua.count()\n",
    "print(\"percent of high prob CUA:\"); (high_prob_cua_count/CUA_count *100)\n",
    "\n",
    "#percent of high prob CUA: 18.09078771695594"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c826fce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "high_prob_non = filter_non.filter((col('prob') > 0.74) & (col('prob') < 0.79))\n",
    "high_non_count=high_prob_non.count()\n",
    "print(\"percent of high prob NON:\"); (high_non_count/non_count *100)\n",
    "\n",
    "#percent of high prob NON: 2.7502071307939544"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ba5d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_high_prob=high_prob_non.union(high_prob_cua)\n",
    "concat_high_pdf=concat_high_prob.toPandas()\n",
    "print(concat_high_pdf.count())\n",
    "print(concat_high_pdf.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbad94a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mid_prob_cua = filter_CUA.filter((col('prob') > 0.68) & (col('prob') < 0.74))\n",
    "mid_prob_cua_count=mid_prob_cua.count()\n",
    "print(\"percent of mid prob CUA:\"); (mid_prob_cua_count/CUA_count *100)\n",
    "\n",
    "#percent of mid prob CUA: 19.27130911390626"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976ff8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mid_prob_non = filter_non.filter((col('prob') > 0.68) & (col('prob') < 0.74))\n",
    "mid_prob_non_count=mid_prob_non.count()\n",
    "print(\"percent of mid prob non:\"); (mid_prob_non_count/non_count *100)\n",
    "\n",
    "#percent of mid prob non: 3.8557980680282933\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ae8182",
   "metadata": {},
   "outputs": [],
   "source": [
    "##control population so large that it require random sample, or will not run in pandas\n",
    "\n",
    "random_mid_prob_sample = mid_prob_non.sample(fraction=200000 / mid_prob_non.count(), withReplacement=False)\n",
    "concat_mid_prob=random_mid_prob_sample.union(mid_prob_cua)\n",
    "concat_mid_pdf=concat_mid_prob.toPandas()\n",
    "print(concat_mid_pdf.count())\n",
    "print(concat_mid_pdf.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7081d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mid_prob_cua2 = filter_CUA.filter((col('prob') > 0.51) & (col('prob') < 0.68))\n",
    "mid_prob_cua_count2=mid_prob_cua2.count()\n",
    "print(\"percent of mid prob CUA2:\"); (mid_prob_cua_count2/CUA_count *100)\n",
    "\n",
    "#percent of mid prob CUA2: 18.298081652729955"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d421e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mid_prob_non2 = filter_non.filter((col('prob') > 0.51) & (col('prob') < 0.68))\n",
    "mid_prob_non_count2=mid_prob_non2.count()\n",
    "print(\"percent of mid prob non:\"); (mid_prob_non_count2/non_count *100)\n",
    "\n",
    "#percent of mid prob non: 5.5574400797277645"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58527ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_mid_prob_sample2 = mid_prob_non2.sample(fraction=200000 / mid_prob_non2.count(), withReplacement=False)\n",
    "concat_mid_prob2=random_mid_prob_sample2.union(mid_prob_cua2)\n",
    "concat_mid_pdf2=concat_mid_prob2.toPandas()\n",
    "print(concat_mid_pdf2.count())\n",
    "print(concat_mid_pdf2.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6001692c",
   "metadata": {},
   "outputs": [],
   "source": [
    "low_prob_cua = filter_CUA.filter((col('prob1') > 0.46) & (col('prob1') < 0.51))\n",
    "low_cua_count=low_prob_cua.count()\n",
    "print(\"percent of low prob CUA:\"); (low_cua_count/CUA_count *100)\n",
    "\n",
    "#percent of low prob CUA: 18.55807743658211"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b65a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "low_prob_non = filter_non.filter((col('prob1') > 0.46) & (col('prob1') < 0.51))\n",
    "low_non_count=low_prob_non.count()\n",
    "print(\"percent of low prob NON:\"); (low_non_count/non_count *100)\n",
    "\n",
    "#percent of low prob NON: 17.44869052128403"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8b61e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_low_prob_sample = low_prob_non.sample(fraction=250000 / low_prob_non.count(), withReplacement=False)\n",
    "concat_low_prob=random_low_prob_sample.union(low_prob_cua)\n",
    "concat_low_pdf=concat_low_prob.toPandas()\n",
    "print(concat_low_pdf.count())\n",
    "print(concat_low_pdf.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004cd52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "low_prob_cua2 = filter_CUA.filter((col('prob1') < 0.46))\n",
    "low_cua_count2=low_prob_cua2.count()\n",
    "print(\"percent of low prob CUA:\"); (low_cua_count2/CUA_count *100)\n",
    "\n",
    "#percent of low prob CUA: 15.185159159581197"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7394a987",
   "metadata": {},
   "outputs": [],
   "source": [
    "low_prob_non2 = filter_non.filter((col('prob1') < 0.46))\n",
    "low_non_count2=low_prob_non2.count()\n",
    "print(\"percent of low prob NON:\"); (low_non_count2/non_count *100)\n",
    "\n",
    "#percent of low prob NON:\n",
    "69.69469490179104"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83dc7839",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_low_prob_sample2 = low_prob_non2.sample(fraction=200000 / low_prob_non2.count(), withReplacement=False)\n",
    "concat_low_prob2=random_low_prob_sample2.union(low_prob_cua2)\n",
    "concat_low_pdf2=concat_low_prob2.toPandas()\n",
    "print(concat_low_pdf2.count())\n",
    "print(concat_low_pdf2.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d26bd4a",
   "metadata": {},
   "source": [
    "## PS Matching with KNN "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d45e53a",
   "metadata": {},
   "source": [
    "### Match on Low Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35de281",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Set 1\n",
    "\n",
    "# Separate data by treatment and control\n",
    "control_data = concat_low_pdf[concat_low_pdf['CUA_ANY'] == 0]['prob']\n",
    "treatment_data = concat_low_pdf[concat_low_pdf['CUA_ANY'] == 1]['prob']\n",
    "\n",
    "# Create histograms for treatment and control groups\n",
    "plt.hist(control_data, alpha=0.5, label='Control')\n",
    "plt.hist(treatment_data, alpha=0.5, label='Treatment')\n",
    "\n",
    "plt.xlabel('Propensity Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8414fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming propensity scores are stored in the 'prob' column \n",
    "# Assuming 'cua_any' column indicates treatment group (1 for treatment, 0 for control)\n",
    "treatment_df = concat_low_pdf[concat_low_pdf['CUA_ANY'] == 1].copy()\n",
    "control_df = concat_low_pdf[concat_low_pdf['CUA_ANY'] == 0].copy()\n",
    "\n",
    "# Fit Nearest Neighbors classifier for control group\n",
    "n_neighbors = 1\n",
    "knn = NearestNeighbors(n_neighbors=n_neighbors)\n",
    "knn.fit(control_df[['prob']])  # Fit on control propensity scores\n",
    "\n",
    "# Find nearest neighbors for treatment group\n",
    "distances, indices = knn.kneighbors(treatment_df[['prob']])\n",
    "\n",
    "# Keep track of used control IDs\n",
    "used_control_ids = set()\n",
    "\n",
    "# Initialize lists to store matched indices\n",
    "matched_control_indices = []\n",
    "matched_treatment_indices = []\n",
    "\n",
    "# Iterate through treatment samples and find nearest neighbor in control group\n",
    "for i, neighbors in enumerate(indices):\n",
    "    nearest_control_index = neighbors[0]  # Retrieve the index of the nearest neighbor\n",
    "    control_id = control_df.iloc[nearest_control_index]['personid']\n",
    "    if control_id not in used_control_ids:\n",
    "        matched_control_indices.append(nearest_control_index)\n",
    "        matched_treatment_indices.append(i)\n",
    "        used_control_ids.add(control_id)  # Mark control ID as used\n",
    "\n",
    "# Create a DataFrame containing treatment and matched control individuals\n",
    "matched_df = pd.DataFrame({\n",
    "    'Treatment_PersonID': treatment_df.iloc[matched_treatment_indices]['personid'].values,\n",
    "    'Treatment_Propensity_Score': treatment_df.iloc[matched_treatment_indices]['prob'].values,\n",
    "    'Control_PersonID': control_df.iloc[matched_control_indices]['personid'].values,\n",
    "    'Control_Propensity_Score': control_df.iloc[matched_control_indices]['prob'].values\n",
    "})\n",
    "\n",
    "# Print the matched DataFrame\n",
    "print(matched_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2ea9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming propensity scores are stored in the 'prob' column \n",
    "# Assuming 'cua_any' column indicates treatment group (1 for treatment, 0 for control)\n",
    "treatment_df = concat_low_pdf[concat_low_pdf['CUA_ANY'] == 1].copy()\n",
    "control_df = concat_low_pdf[concat_low_pdf['CUA_ANY'] == 0].copy()\n",
    "\n",
    "# Fit Nearest Neighbors classifier for control group\n",
    "n_neighbors = len(control_df)  # Set number of neighbors to the size of control group\n",
    "knn = NearestNeighbors(n_neighbors=n_neighbors)\n",
    "knn.fit(control_df[['prob']])  # Fit on control propensity scores\n",
    "\n",
    "# Find nearest neighbors for treatment group\n",
    "distances, indices = knn.kneighbors(treatment_df[['prob']])\n",
    "\n",
    "# Keep track of used control IDs\n",
    "used_control_ids = set()\n",
    "\n",
    "# Initialize lists to store matched indices\n",
    "matched_control_indices = []\n",
    "matched_treatment_indices = []\n",
    "\n",
    "# Iterate through treatment samples and find nearest neighbor in control group\n",
    "for i, neighbors in enumerate(indices):\n",
    "    for nearest_control_index in neighbors:  # Iterate over neighbors\n",
    "        control_id = control_df.iloc[nearest_control_index]['personid']\n",
    "        if control_id not in used_control_ids:\n",
    "            matched_control_indices.append(nearest_control_index)\n",
    "            matched_treatment_indices.append(i)\n",
    "            used_control_ids.add(control_id)  # Mark control ID as used\n",
    "            break  # Move to the next treatment individual\n",
    "\n",
    "# Create a DataFrame containing treatment and matched control individuals\n",
    "matched_df = pd.DataFrame({\n",
    "    'Treatment_PersonID': treatment_df.iloc[matched_treatment_indices]['personid'].values,\n",
    "    'Treatment_Propensity_Score': treatment_df.iloc[matched_treatment_indices]['prob'].values,\n",
    "    'Control_PersonID': control_df.iloc[matched_control_indices]['personid'].values,\n",
    "    'Control_Propensity_Score': control_df.iloc[matched_control_indices]['prob'].values\n",
    "})\n",
    "\n",
    "# Print the matched DataFrame\n",
    "print(matched_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ffeda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9c71b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_df.count()\n",
    "#5282"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71bc1475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values (NAs) in the 'Control_PersonID' column\n",
    "missing_values = matched_df['Control_PersonID'].isna().sum()\n",
    "print(\"Number of missing values in 'Control_PersonID' column:\", missing_values)\n",
    "\n",
    "# Check for duplicates in the 'Control_PersonID' column\n",
    "duplicate_count = matched_df.duplicated(subset=['Control_PersonID']).sum()\n",
    "print(\"Number of duplicate IDs in 'Control_PersonID' column:\", duplicate_count)\n",
    "\n",
    "#Number of missing values in 'Control_PersonID' column: 0\n",
    "#Number of duplicate IDs in 'Control_PersonID' column: 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27833c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Show the After histogram\n",
    "\n",
    "# Filter propensity scores for treatment and control groups\n",
    "treatment_scores = matched_df['Treatment_Propensity_Score']\n",
    "control_scores = matched_df['Control_Propensity_Score']\n",
    "\n",
    "# Plot histograms\n",
    "##Adjust alpha\n",
    "plt.hist(treatment_scores, bins=20, alpha=0.3, label='Treatment')\n",
    "plt.hist(control_scores, bins=20, alpha=0.3, label='Control')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Propensity Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of Matched Propensity Scores by Treatment vs. Control')\n",
    "\n",
    "# Add legend\n",
    "plt.legend()\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f44a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the absolute difference in propensity scores between treatment and control\n",
    "matched_df['Propensity_Score_Difference'] = abs(matched_df['Treatment_Propensity_Score'] - matched_df['Control_Propensity_Score'])\n",
    "\n",
    "# Maximum difference\n",
    "max_difference = matched_df['Propensity_Score_Difference'].max()\n",
    "\n",
    "# Average difference\n",
    "avg_difference = matched_df['Propensity_Score_Difference'].mean()\n",
    "\n",
    "print(\"Maximum Difference in Propensity Scores:\", max_difference)\n",
    "print(\"Average Difference in Propensity Scores:\", avg_difference)\n",
    "\n",
    "#Maximum Difference in Propensity Scores: 9.384839348480778e-05\n",
    "#Average Difference in Propensity Scores: 2.2879055039834536e-07"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0754b4",
   "metadata": {},
   "source": [
    "### Match on Low2 Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54702f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Set 2\n",
    "\n",
    "# Separate data by treatment and control\n",
    "control_data = concat_low_pdf2[concat_low_pdf2['CUA_ANY'] == 0]['prob']\n",
    "treatment_data = concat_low_pdf2[concat_low_pdf2['CUA_ANY'] == 1]['prob']\n",
    "\n",
    "# Create histograms for treatment and control groups\n",
    "plt.hist(control_data, alpha=0.5, label='Control')\n",
    "plt.hist(treatment_data, alpha=0.5, label='Treatment')\n",
    "\n",
    "plt.xlabel('Propensity Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eefdd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Assuming propensity scores are stored in the 'prob' column of concat_low_pdf\n",
    "# Assuming 'cua_any' column indicates treatment group (1 for treatment, 0 for control)\n",
    "treatment_df2 = concat_low_pdf2[concat_low_pdf2['CUA_ANY'] == 1].copy()\n",
    "control_df2 = concat_low_pdf2[concat_low_pdf2['CUA_ANY'] == 0].copy()\n",
    "\n",
    "# Fit Nearest Neighbors classifier for control group\n",
    "n_neighbors2 = len(control_df2)  # Set number of neighbors to the size of control group\n",
    "knn2 = NearestNeighbors(n_neighbors=n_neighbors2)\n",
    "knn2.fit(control_df2[['prob']])  # Fit on control propensity scores\n",
    "\n",
    "# Find nearest neighbors for treatment group\n",
    "distances, indices = knn2.kneighbors(treatment_df2[['prob']])\n",
    "\n",
    "# Keep track of used control IDs\n",
    "used_control_ids2 = set()\n",
    "\n",
    "# Initialize lists to store matched indices\n",
    "matched_control_indices2 = []\n",
    "matched_treatment_indices2 = []\n",
    "\n",
    "# Iterate through treatment samples and find nearest neighbor in control group\n",
    "for i, neighbors in enumerate(indices):\n",
    "    for nearest_control_index2 in neighbors:  # Iterate over neighbors\n",
    "        control_id2 = control_df2.iloc[nearest_control_index2]['personid']\n",
    "        if control_id2 not in used_control_ids2:\n",
    "            matched_control_indices2.append(nearest_control_index2)\n",
    "            matched_treatment_indices2.append(i)\n",
    "            used_control_ids2.add(control_id2)  # Mark control ID as used\n",
    "            break  # Move to the next treatment individual\n",
    "\n",
    "# Create a DataFrame containing treatment and matched control individuals\n",
    "matched_df2 = pd.DataFrame({\n",
    "    'Treatment_PersonID': treatment_df2.iloc[matched_treatment_indices2]['personid'].values,\n",
    "    'Treatment_Propensity_Score': treatment_df2.iloc[matched_treatment_indices2]['prob'].values,\n",
    "    'Control_PersonID': control_df2.iloc[matched_control_indices2]['personid'].values,\n",
    "    'Control_Propensity_Score': control_df2.iloc[matched_control_indices2]['prob'].values\n",
    "})\n",
    "\n",
    "# Print the matched DataFrame\n",
    "print(matched_df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b766761",
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_df2.count()\n",
    "##4322"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74bea2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values (NAs) in the 'Control_PersonID' column\n",
    "missing_values = matched_df2['Control_PersonID'].isna().sum()\n",
    "print(\"Number of missing values in 'Control_PersonID' column:\", missing_values)\n",
    "\n",
    "# Check for duplicates in the 'Control_PersonID' column\n",
    "duplicate_count = matched_df2.duplicated(subset=['Control_PersonID']).sum()\n",
    "print(\"Number of duplicate IDs in 'Control_PersonID' column:\", duplicate_count)\n",
    "\n",
    "#Number of missing values in 'Control_PersonID' column: 0\n",
    "#Number of duplicate IDs in 'Control_PersonID' column: 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe458dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter propensity scores for treatment and control groups\n",
    "treatment_scores = matched_df2['Treatment_Propensity_Score']\n",
    "control_scores = matched_df2['Control_Propensity_Score']\n",
    "\n",
    "# Plot histograms\n",
    "plt.hist(treatment_scores, bins=20, alpha=0.3, label='Treatment')\n",
    "plt.hist(control_scores, bins=20, alpha=0.3, label='Control')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Propensity Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of Matched Propensity Scores by Treatment vs. Control')\n",
    "\n",
    "# Add legend\n",
    "plt.legend()\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1dbad42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the absolute difference in propensity scores between treatment and control\n",
    "matched_df2['Propensity_Score_Difference'] = abs(matched_df2['Treatment_Propensity_Score'] - matched_df2['Control_Propensity_Score'])\n",
    "\n",
    "# Maximum difference\n",
    "max_difference = matched_df2['Propensity_Score_Difference'].max()\n",
    "\n",
    "# Average difference\n",
    "avg_difference = matched_df2['Propensity_Score_Difference'].mean()\n",
    "\n",
    "print(\"Maximum Difference in Propensity Scores:\", max_difference)\n",
    "print(\"Average Difference in Propensity Scores:\", avg_difference)\n",
    "\n",
    "#Maximum Difference in Propensity Scores: 0.00016796650844513872\n",
    "#Average Difference in Propensity Scores: 1.7268268506190105e-06"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d531f32",
   "metadata": {},
   "source": [
    "### Concatenate Low & Low2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b817919b",
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_low_match = pd.concat([matched_df, matched_df2], ignore_index=True)\n",
    "concatenated_low_match.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1faf6bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(concatenated_low_match))\n",
    "print(low_cua_count + low_cua_count2)\n",
    "#9604\n",
    "#9604"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a11a3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Pandas DataFrame to Spark DataFrame\n",
    "spark_low_match = spark.createDataFrame(concatenated_low_match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a83dc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6f324563",
   "metadata": {},
   "source": [
    "### Match on Mid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43aeca1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate data by treatment and control\n",
    "control_data = concat_mid_pdf[concat_mid_pdf['CUA_ANY'] == 0]['prob']\n",
    "treatment_data = concat_mid_pdf[concat_mid_pdf['CUA_ANY'] == 1]['prob']\n",
    "\n",
    "# Create histograms for treatment and control groups\n",
    "plt.hist(control_data, alpha=0.5, label='Control')\n",
    "plt.hist(treatment_data, alpha=0.5, label='Treatment')\n",
    "\n",
    "plt.xlabel('Propensity Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf8961e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming propensity scores are stored in the 'prob' column of concat_low_pdf\n",
    "# Assuming 'cua_any' column indicates treatment group (1 for treatment, 0 for control)\n",
    "treatment_df3 = concat_mid_pdf[concat_mid_pdf['CUA_ANY'] == 1].copy()\n",
    "control_df3 = concat_mid_pdf[concat_mid_pdf['CUA_ANY'] == 0].copy()\n",
    "\n",
    "# Fit Nearest Neighbors classifier for control group\n",
    "n_neighbors3 = len(control_df3)  # Set number of neighbors to the size of control group\n",
    "knn3 = NearestNeighbors(n_neighbors=n_neighbors3)\n",
    "knn3.fit(control_df3[['prob']])  # Fit on control propensity scores\n",
    "\n",
    "# Find nearest neighbors for treatment group\n",
    "distances, indices = knn3.kneighbors(treatment_df3[['prob']])\n",
    "\n",
    "# Keep track of used control IDs\n",
    "used_control_ids3 = set()\n",
    "\n",
    "# Initialize lists to store matched indices\n",
    "matched_control_indices3 = []\n",
    "matched_treatment_indices3 = []\n",
    "\n",
    "# Iterate through treatment samples and find nearest neighbor in control group\n",
    "for i, neighbors in enumerate(indices):\n",
    "    for nearest_control_index3 in neighbors:  # Iterate over neighbors\n",
    "        control_id3 = control_df3.iloc[nearest_control_index3]['personid']\n",
    "        if control_id3 not in used_control_ids3:\n",
    "            matched_control_indices3.append(nearest_control_index3)\n",
    "            matched_treatment_indices3.append(i)\n",
    "            used_control_ids3.add(control_id3)  # Mark control ID as used\n",
    "            break  # Move to the next treatment individual\n",
    "\n",
    "# Create a DataFrame containing treatment and matched control individuals\n",
    "matched_df3 = pd.DataFrame({\n",
    "    'Treatment_PersonID': treatment_df3.iloc[matched_treatment_indices3]['personid'].values,\n",
    "    'Treatment_Propensity_Score': treatment_df3.iloc[matched_treatment_indices3]['prob'].values,\n",
    "    'Control_PersonID': control_df3.iloc[matched_control_indices3]['personid'].values,\n",
    "    'Control_Propensity_Score': control_df3.iloc[matched_control_indices3]['prob'].values\n",
    "})\n",
    "\n",
    "# Print the matched DataFrame\n",
    "print(matched_df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c1079d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values (NAs) in the 'Control_PersonID' column\n",
    "missing_values = matched_df3['Control_PersonID'].isna().sum()\n",
    "print(\"Number of missing values in 'Control_PersonID' column:\", missing_values)\n",
    "\n",
    "# Check for duplicates in the 'Control_PersonID' column\n",
    "duplicate_count = matched_df3.duplicated(subset=['Control_PersonID']).sum()\n",
    "print(\"Number of duplicate IDs in 'Control_PersonID' column:\", duplicate_count)\n",
    "\n",
    "#Number of missing values in 'Control_PersonID' column: 0\n",
    "#Number of duplicate IDs in 'Control_PersonID' column: 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ab2269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter propensity scores for treatment and control groups\n",
    "treatment_scores = matched_df3['Treatment_Propensity_Score']\n",
    "control_scores = matched_df3['Control_Propensity_Score']\n",
    "\n",
    "# Plot histograms\n",
    "plt.hist(treatment_scores, bins=20, alpha=0.3, label='Treatment')\n",
    "plt.hist(control_scores, bins=20, alpha=0.3, label='Control')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Propensity Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of Matched Propensity Scores by Treatment vs. Control')\n",
    "\n",
    "# Add legend\n",
    "plt.legend()\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f285290",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the absolute difference in propensity scores between treatment and control\n",
    "matched_df3['Propensity_Score_Difference'] = abs(matched_df3['Treatment_Propensity_Score'] - matched_df3['Control_Propensity_Score'])\n",
    "\n",
    "# Maximum difference\n",
    "max_difference = matched_df3['Propensity_Score_Difference'].max()\n",
    "\n",
    "# Average difference\n",
    "avg_difference = matched_df3['Propensity_Score_Difference'].mean()\n",
    "\n",
    "print(\"Maximum Difference in Propensity Scores:\", max_difference)\n",
    "print(\"Average Difference in Propensity Scores:\", avg_difference)\n",
    "\n",
    "#Maximum Difference in Propensity Scores: 1.3726183205164944e-05\n",
    "#Average Difference in Propensity Scores: 1.6642898049665893e-07"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3c4a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate data by treatment and control\n",
    "control_data = concat_mid_pdf2[concat_mid_pdf2['CUA_ANY'] == 0]['prob']\n",
    "treatment_data = concat_mid_pdf2[concat_mid_pdf2['CUA_ANY'] == 1]['prob']\n",
    "\n",
    "# Create histograms for treatment and control groups\n",
    "plt.hist(control_data, alpha=0.5, label='Control')\n",
    "plt.hist(treatment_data, alpha=0.5, label='Treatment')\n",
    "\n",
    "plt.xlabel('Propensity Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b240bc",
   "metadata": {},
   "source": [
    "### Match for Mid2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d768b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming propensity scores are stored in the 'prob' column \n",
    "# Assuming 'cua_any' column indicates treatment group (1 for treatment, 0 for control)\n",
    "treatment_df4 = concat_mid_pdf2[concat_mid_pdf2['CUA_ANY'] == 1].copy()\n",
    "control_df4 = concat_mid_pdf2[concat_mid_pdf2['CUA_ANY'] == 0].copy()\n",
    "\n",
    "# Fit Nearest Neighbors classifier for control group\n",
    "n_neighbors4 = len(control_df4)  # Set number of neighbors to the size of control group\n",
    "knn4 = NearestNeighbors(n_neighbors=n_neighbors4)\n",
    "knn4.fit(control_df4[['prob']])  # Fit on control propensity scores\n",
    "\n",
    "# Find nearest neighbors for treatment group\n",
    "distances, indices = knn4.kneighbors(treatment_df4[['prob']])\n",
    "\n",
    "# Keep track of used control IDs\n",
    "used_control_ids4 = set()\n",
    "\n",
    "# Initialize lists to store matched indices\n",
    "matched_control_indices4 = []\n",
    "matched_treatment_indices4 = []\n",
    "\n",
    "# Iterate through treatment samples and find nearest neighbor in control group\n",
    "for i, neighbors in enumerate(indices):\n",
    "    for nearest_control_index4 in neighbors:  # Iterate over neighbors\n",
    "        control_id4 = control_df4.iloc[nearest_control_index4]['personid']\n",
    "        if control_id4 not in used_control_ids4:\n",
    "            matched_control_indices4.append(nearest_control_index4)\n",
    "            matched_treatment_indices4.append(i)\n",
    "            used_control_ids4.add(control_id4)  # Mark control ID as used\n",
    "            break  # Move to the next treatment individual\n",
    "\n",
    "# Create a DataFrame containing treatment and matched control individuals\n",
    "matched_df4 = pd.DataFrame({\n",
    "    'Treatment_PersonID': treatment_df4.iloc[matched_treatment_indices4]['personid'].values,\n",
    "    'Treatment_Propensity_Score': treatment_df4.iloc[matched_treatment_indices4]['prob'].values,\n",
    "    'Control_PersonID': control_df4.iloc[matched_control_indices4]['personid'].values,\n",
    "    'Control_Propensity_Score': control_df4.iloc[matched_control_indices4]['prob'].values\n",
    "})\n",
    "\n",
    "# Print the matched DataFrame\n",
    "print(matched_df4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2e631f",
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_df4.count()\n",
    "#5208"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c9fb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values (NAs) in the 'Control_PersonID' column\n",
    "missing_values = matched_df4['Control_PersonID'].isna().sum()\n",
    "print(\"Number of missing values in 'Control_PersonID' column:\", missing_values)\n",
    "\n",
    "# Check for duplicates in the 'Control_PersonID' column\n",
    "duplicate_count = matched_df4.duplicated(subset=['Control_PersonID']).sum()\n",
    "print(\"Number of duplicate IDs in 'Control_PersonID' column:\", duplicate_count)\n",
    "\n",
    "#Number of missing values in 'Control_PersonID' column: 0\n",
    "#Number of duplicate IDs in 'Control_PersonID' column: 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca82e320",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter propensity scores for treatment and control groups\n",
    "treatment_scores = matched_df4['Treatment_Propensity_Score']\n",
    "control_scores = matched_df4['Control_Propensity_Score']\n",
    "\n",
    "# Plot histograms\n",
    "plt.hist(treatment_scores, bins=20, alpha=0.3, label='Treatment')\n",
    "plt.hist(control_scores, bins=20, alpha=0.3, label='Control')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Propensity Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of Matched Propensity Scores by Treatment vs. Control')\n",
    "\n",
    "# Add legend\n",
    "plt.legend()\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0198ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the absolute difference in propensity scores between treatment and control\n",
    "matched_df4['Propensity_Score_Difference'] = abs(matched_df4['Treatment_Propensity_Score'] - matched_df4['Control_Propensity_Score'])\n",
    "\n",
    "# Maximum difference\n",
    "max_difference = matched_df4['Propensity_Score_Difference'].max()\n",
    "\n",
    "# Average difference\n",
    "avg_difference = matched_df4['Propensity_Score_Difference'].mean()\n",
    "\n",
    "print(\"Maximum Difference in Propensity Scores:\", max_difference)\n",
    "print(\"Average Difference in Propensity Scores:\", avg_difference)\n",
    "\n",
    "#Maximum Difference in Propensity Scores: 2.966165954598754e-05\n",
    "#Average Difference in Propensity Scores: 6.579066603665349e-07"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4771f482",
   "metadata": {},
   "source": [
    "### Concatenate Mid & Mid2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c75c92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_mid_match = pd.concat([matched_df3, matched_df4], ignore_index=True)\n",
    "print(len(concatenated_mid_match))\n",
    "print(mid_prob_cua_count + mid_prob_cua_count2)\n",
    "\n",
    "#10693\n",
    "#10693"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac4cbc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Pandas DataFrame to Spark DataFrame\n",
    "spark_mid_match = spark.createDataFrame(concatenated_mid_match)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a0528d",
   "metadata": {},
   "source": [
    "### Match on High"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6e9a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate data by treatment and control\n",
    "control_data = concat_highest_pdf[concat_highest_pdf['CUA_ANY'] == 0]['prob']\n",
    "treatment_data = concat_highest_pdf[concat_highest_pdf['CUA_ANY'] == 1]['prob']\n",
    "\n",
    "# Create histograms for treatment and control groups\n",
    "plt.hist(control_data, alpha=0.5, label='Control')\n",
    "plt.hist(treatment_data, alpha=0.5, label='Treatment')\n",
    "\n",
    "plt.xlabel('Propensity Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f22ebfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming propensity scores are stored in the 'prob' column \n",
    "# Assuming 'cua_any' column indicates treatment group (1 for treatment, 0 for control)\n",
    "treatment_df5 = concat_highest_pdf[concat_highest_pdf['CUA_ANY'] == 1].copy()\n",
    "control_df5 = concat_highest_pdf[concat_highest_pdf['CUA_ANY'] == 0].copy()\n",
    "\n",
    "# Fit Nearest Neighbors classifier for control group\n",
    "n_neighbors5 = len(control_df5)  # Set number of neighbors to the size of control group\n",
    "knn5 = NearestNeighbors(n_neighbors=n_neighbors5)\n",
    "knn5.fit(control_df5[['prob']])  # Fit on control propensity scores\n",
    "\n",
    "# Find nearest neighbors for treatment group\n",
    "distances, indices = knn5.kneighbors(treatment_df5[['prob']])\n",
    "\n",
    "# Keep track of used control IDs\n",
    "used_control_ids5 = set()\n",
    "\n",
    "# Initialize lists to store matched indices\n",
    "matched_control_indices5 = []\n",
    "matched_treatment_indices5 = []\n",
    "\n",
    "# Iterate through treatment samples and find nearest neighbor in control group\n",
    "for i, neighbors in enumerate(indices):\n",
    "    for nearest_control_index5 in neighbors:  # Iterate over neighbors\n",
    "        control_id5 = control_df5.iloc[nearest_control_index5]['personid']\n",
    "        if control_id5 not in used_control_ids5:\n",
    "            matched_control_indices5.append(nearest_control_index5)\n",
    "            matched_treatment_indices5.append(i)\n",
    "            used_control_ids5.add(control_id5)  # Mark control ID as used\n",
    "            break  # Move to the next treatment individual\n",
    "\n",
    "# Create a DataFrame containing treatment and matched control individuals\n",
    "matched_df5 = pd.DataFrame({\n",
    "    'Treatment_PersonID': treatment_df5.iloc[matched_treatment_indices5]['personid'].values,\n",
    "    'Treatment_Propensity_Score': treatment_df5.iloc[matched_treatment_indices5]['prob'].values,\n",
    "    'Control_PersonID': control_df5.iloc[matched_control_indices5]['personid'].values,\n",
    "    'Control_Propensity_Score': control_df5.iloc[matched_control_indices5]['prob'].values\n",
    "})\n",
    "\n",
    "# Print the matched DataFrame\n",
    "print(matched_df5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f41e3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_df5.count()\n",
    "\n",
    "#3016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506e7d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter propensity scores for treatment and control groups\n",
    "treatment_scores = matched_df5['Treatment_Propensity_Score']\n",
    "control_scores = matched_df5['Control_Propensity_Score']\n",
    "\n",
    "# Plot histograms\n",
    "plt.hist(treatment_scores, bins=20, alpha=0.3, label='Treatment')\n",
    "plt.hist(control_scores, bins=20, alpha=0.3, label='Control')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Propensity Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of Matched Propensity Scores by Treatment vs. Control')\n",
    "\n",
    "# Add legend\n",
    "plt.legend()\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13656bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the absolute difference in propensity scores between treatment and control\n",
    "matched_df5['Propensity_Score_Difference'] = abs(matched_df5['Treatment_Propensity_Score'] - matched_df5['Control_Propensity_Score'])\n",
    "\n",
    "# Maximum difference\n",
    "max_difference = matched_df5['Propensity_Score_Difference'].max()\n",
    "\n",
    "# Average difference\n",
    "avg_difference = matched_df5['Propensity_Score_Difference'].mean()\n",
    "\n",
    "print(\"Maximum Difference in Propensity Scores:\", max_difference)\n",
    "print(\"Average Difference in Propensity Scores:\", avg_difference)\n",
    "\n",
    "#Maximum Difference in Propensity Scores: 0.0002882994803843353\n",
    "#Average Difference in Propensity Scores: 6.399843397289812e-07\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f2f948",
   "metadata": {},
   "source": [
    "### Match on Highest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece0d426",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate data by treatment and control\n",
    "control_data = concat_high_pdf[concat_high_pdf['CUA_ANY'] == 0]['prob']\n",
    "treatment_data = concat_high_pdf[concat_high_pdf['CUA_ANY'] == 1]['prob']\n",
    "\n",
    "# Create histograms for treatment and control groups\n",
    "plt.hist(control_data, alpha=0.5, label='Control')\n",
    "plt.hist(treatment_data, alpha=0.5, label='Treatment')\n",
    "\n",
    "plt.xlabel('Propensity Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5b53cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming propensity scores are stored in the 'prob' column \n",
    "# Assuming 'cua_any' column indicates treatment group (1 for treatment, 0 for control)\n",
    "treatment_df6 = concat_high_pdf[concat_high_pdf['CUA_ANY'] == 1].copy()\n",
    "control_df6 = concat_high_pdf[concat_high_pdf['CUA_ANY'] == 0].copy()\n",
    "\n",
    "# Fit Nearest Neighbors classifier for control group\n",
    "n_neighbors6 = len(control_df6)  # Set number of neighbors to the size of control group\n",
    "knn6 = NearestNeighbors(n_neighbors=n_neighbors6)\n",
    "knn6.fit(control_df6[['prob']])  # Fit on control propensity scores\n",
    "\n",
    "# Find nearest neighbors for treatment group\n",
    "distances, indices = knn6.kneighbors(treatment_df6[['prob']])\n",
    "\n",
    "# Keep track of used control IDs\n",
    "used_control_ids6 = set()\n",
    "\n",
    "# Initialize lists to store matched indices\n",
    "matched_control_indices6 = []\n",
    "matched_treatment_indices6 = []\n",
    "\n",
    "# Iterate through treatment samples and find nearest neighbor in control group\n",
    "for i, neighbors in enumerate(indices):\n",
    "    for nearest_control_index6 in neighbors:  # Iterate over neighbors\n",
    "        control_id6 = control_df6.iloc[nearest_control_index6]['personid']\n",
    "        if control_id6 not in used_control_ids6:\n",
    "            matched_control_indices6.append(nearest_control_index6)\n",
    "            matched_treatment_indices6.append(i)\n",
    "            used_control_ids6.add(control_id6)  # Mark control ID as used\n",
    "            break  # Move to the next treatment individual\n",
    "\n",
    "# Create a DataFrame containing treatment and matched control individuals\n",
    "matched_df6 = pd.DataFrame({\n",
    "    'Treatment_PersonID': treatment_df6.iloc[matched_treatment_indices6]['personid'].values,\n",
    "    'Treatment_Propensity_Score': treatment_df6.iloc[matched_treatment_indices6]['prob'].values,\n",
    "    'Control_PersonID': control_df6.iloc[matched_control_indices6]['personid'].values,\n",
    "    'Control_Propensity_Score': control_df6.iloc[matched_control_indices6]['prob'].values\n",
    "})\n",
    "\n",
    "# Print the matched DataFrame\n",
    "print(matched_df6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a37594",
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_df6.count()\n",
    "## 5149"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a743577b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter propensity scores for treatment and control groups\n",
    "treatment_scores = matched_df6['Treatment_Propensity_Score']\n",
    "control_scores = matched_df6['Control_Propensity_Score']\n",
    "\n",
    "# Plot histograms\n",
    "plt.hist(treatment_scores, bins=20, alpha=0.3, label='Treatment')\n",
    "plt.hist(control_scores, bins=20, alpha=0.3, label='Control')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Propensity Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of Matched Propensity Scores by Treatment vs. Control')\n",
    "\n",
    "# Add legend\n",
    "plt.legend()\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24fd6e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the absolute difference in propensity scores between treatment and control\n",
    "matched_df6['Propensity_Score_Difference'] = abs(matched_df6['Treatment_Propensity_Score'] - matched_df6['Control_Propensity_Score'])\n",
    "\n",
    "# Maximum difference\n",
    "max_difference = matched_df6['Propensity_Score_Difference'].max()\n",
    "\n",
    "# Average difference\n",
    "avg_difference = matched_df6['Propensity_Score_Difference'].mean()\n",
    "\n",
    "print(\"Maximum Difference in Propensity Scores:\", max_difference)\n",
    "print(\"Average Difference in Propensity Scores:\", avg_difference)\n",
    "\n",
    "#Maximum Difference in Propensity Scores: 3.6452751333015954e-06\n",
    "#Average Difference in Propensity Scores: 4.993818770897132e-08"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02819bd",
   "metadata": {},
   "source": [
    "### Concatenate High & Highest Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b391ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_high_match = pd.concat([matched_df5, matched_df6], ignore_index=True)\n",
    "print(len(concatenated_high_match))\n",
    "print(high_prob_cua_count + highest_cua_count)\n",
    "\n",
    "#8165\n",
    "#8165"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05febf6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_high_match = spark.createDataFrame(concatenated_high_match)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e262dc8",
   "metadata": {},
   "source": [
    "### Concatenate the various matches DFs to save as one table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1075de58",
   "metadata": {},
   "outputs": [],
   "source": [
    "high_mid=spark_high_match.union(spark_mid_match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353bd063",
   "metadata": {},
   "outputs": [],
   "source": [
    "high_low=high_mid.union(spark_low_match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c024b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "high_low.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e43d2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "high_low.write.saveAsTable('CUA_db.ps_matches_updated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b7ab47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
