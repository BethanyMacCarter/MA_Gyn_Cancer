{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d20b587",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a90b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set max columns, rows, column width in pandas so doesn't truncate\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth',250) # or -1\n",
    "pd.set_option('display.max_columns', None) # or 500\n",
    "pd.set_option('display.max_rows', None) # or 500\n",
    "\n",
    "# sets the cell width to 100% respective to the screen size\n",
    "from IPython.core.display import display, HTML\n",
    "from pyspark.sql.functions import when, col\n",
    "from pyspark.sql.functions import avg\n",
    "display(HTML(\"<style>.container { width:92% !important; }</style>\"))\n",
    "from pyspark.sql.functions import col, sum as spark_sum\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb89ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, max\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import rank\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23399ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer, OneHotEncoder\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.sql.functions import col, sum as spark_sum\n",
    "import matplotlib.pyplot as plt\n",
    "from pyspark.sql.functions import col, log, exp\n",
    "from pyspark.sql.functions import rand\n",
    "from pyspark.sql import Window\n",
    "from pyspark.sql.functions import row_number\n",
    "from pyspark.sql.functions import col, udf\n",
    "from pyspark.sql.types import DoubleType\n",
    "from pyspark.sql.functions import col, expr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0708a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql('use CUA_db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2295cf8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#call in dataframe\n",
    "\n",
    "cua_non= spark.sql(\"\"\"\n",
    "    SELECT *\n",
    "    FROM concat_cua_non_table\n",
    "\"\"\")\n",
    "cua_non"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4cf5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cua_non.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1c881c",
   "metadata": {},
   "source": [
    "## Alter numerics in Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ecff94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Altering age columns\n",
    "\n",
    "# Dividing by 100\n",
    "scaled_divided = cua_non.withColumn(\"scaled_age\", col(\"age\") / 100)\n",
    "\n",
    "# Taking logarithm\n",
    "scaled_log = scaled_divided.withColumn(\"age_log\", log(col(\"scaled_age\")))\n",
    "\n",
    "\n",
    "# Taking exponentiation\n",
    "scaled_exp = scaled_log.withColumn(\"age_exp\", exp(col(\"scaled_age\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0219d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Altering BMI columns\n",
    "\n",
    "# Dividing by 40 (although higher BMIs, this is a typical high range)\n",
    "scaled_BMI = scaled_exp.withColumn(\"scaled_BMI\", col(\"BMI\") / 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645dabea",
   "metadata": {},
   "source": [
    "## Create DF with equal groups to deal with imbalance classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64baf4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_CUA = scaled_BMI.filter(scaled_BMI['CUA_ANY'] == 1)  # Filter treatment group\n",
    "grouped_non=scaled_BMI.filter(scaled_BMI['CUA_ANY'] == 0)  # Filter control group\n",
    "\n",
    "print(grouped_CUA.count())\n",
    "print(grouped_non.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14498275",
   "metadata": {},
   "outputs": [],
   "source": [
    "## order the grouped non and then randomize\n",
    "ordered_and_randomized_df = grouped_non.orderBy(rand())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e919e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new column named '_index' as an index using row_number\n",
    "window_spec = Window.orderBy(\"personid\")  # Replace \"any_column\" with a column that defines the order\n",
    "df_with_index = ordered_and_randomized_df.withColumn(\"_index\", row_number().over(window_spec))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93fa178",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the total number of rows in the original DataFrame\n",
    "total_rows = df_with_index.count()\n",
    "\n",
    "# Number of rows for each random DataFrame\n",
    "rows_per_dataframe = 28462\n",
    "\n",
    "start_index_df1 = 0\n",
    "end_index_df1 = rows_per_dataframe\n",
    "\n",
    "# Filter the original DataFrame for the first DataFrame\n",
    "df1 = df_with_index.filter((col(\"_index\") >= start_index_df1) & (col(\"_index\") < end_index_df1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ade334",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945d367d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the start and end indices for the second DataFrame\n",
    "start_index_df2 = end_index_df1\n",
    "end_index_df2 = start_index_df2 + rows_per_dataframe\n",
    "\n",
    "# Filter the original DataFrame for the second DataFrame\n",
    "df2 = df_with_index.filter((col(\"_index\") >= start_index_df2) & (col(\"_index\") < end_index_df2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bedbd1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the start and end indices for the third DataFrame\n",
    "start_index_df3 = end_index_df2\n",
    "end_index_df3 = start_index_df3 + rows_per_dataframe\n",
    "\n",
    "# Filter the original DataFrame for the third DataFrame\n",
    "df3 = df_with_index.filter((col(\"_index\") >= start_index_df3) & (col(\"_index\") < end_index_df3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9916b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the start and end indices for the fourth DataFrame\n",
    "start_index_df4 = end_index_df3\n",
    "end_index_df4 = start_index_df4 + rows_per_dataframe\n",
    "\n",
    "# Filter the original DataFrame for the fourth DataFrame\n",
    "df4 = df_with_index.filter((col(\"_index\") >= start_index_df4) & (col(\"_index\") < end_index_df4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0dd3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the start and end indices for the fifth DataFrame\n",
    "start_index_df5 = end_index_df4\n",
    "end_index_df5 = start_index_df5 + rows_per_dataframe\n",
    "\n",
    "# Filter the original DataFrame for the fifth DataFrame\n",
    "df5 = df_with_index.filter((col(\"_index\") >= start_index_df5) & (col(\"_index\") < end_index_df5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe7bb62",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1a=df1.drop('_index')\n",
    "df2a=df2.drop('_index')\n",
    "df3a=df3.drop('_index')\n",
    "df4a=df4.drop('_index')\n",
    "df5a=df5.drop('_index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184efbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Recombine with the CUA df\n",
    "random_non_cua1=grouped_CUA.union(df1a)\n",
    "random_non_cua2=grouped_CUA.union(df2a)\n",
    "random_non_cua3=grouped_CUA.union(df3a)\n",
    "random_non_cua4=grouped_CUA.union(df4a)\n",
    "random_non_cua5=grouped_CUA.union(df5a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c063a0",
   "metadata": {},
   "source": [
    "## RF Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71478f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_cols= ['AIAN', 'NHPI', 'Asian', 'Black', 'White', 'Hisp_Latino',\n",
    "        'Other', 'Mixed', 'Unknown', 'urbn', 'rural', 'no_urban', 'Metropol',\n",
    "        'Non_metro', 'no_metro', 'dead', 'R0', 'R1', 'R2', 'R3', 'R4', 'R5', 'R6', 'R7', 'R8',\n",
    "        'R9', 'RU', 'endo', 'infertility', 'RA', 'dysmen', 'Irregular', 'spinal', 'scoliosis',\n",
    "        'hearing_loss', 'mc', 'EOM', 'hemato', 'HPV', 'HIV', 'STI', 'smoker', 'AA', 'CVD',\n",
    "        'meno', 'preg', 'ectop', 'lynch', 'PCOS','Db2', 'csect', 'ccsect', \n",
    "        'lcsect', 'MCCLD', 'HRP', 'MENA', 'API_ethn', 'PPROM', 'FT_loss','SA']\n",
    "numerical_cols=['scaled_BMI', 'scaled_age', 'age_log', 'age_exp' ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013b085f",
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(\n",
    "    inputCols=binary_cols + numerical_cols, \n",
    "    outputCol=\"features\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d48fae3",
   "metadata": {},
   "source": [
    "## First Run with df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e40560",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the Random Forest model; 500 trees selected based off of article\n",
    "rf = RandomForestClassifier(labelCol=\"CUA_ANY\", featuresCol=\"features\", numTrees=500)\n",
    "\n",
    "##(this can be more complex when you need string indexer and one-hot encoder)\n",
    "pipeline = Pipeline(stages=[assembler, rf])\n",
    "\n",
    "(training_data, testing_data) = random_non_cua1.randomSplit([0.8, 0.2], seed=1234)\n",
    "\n",
    "# Train the model\n",
    "model = pipeline.fit(random_non_cua1)\n",
    "\n",
    "#Make predictions on the testing set\n",
    "predictions = model.transform(testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73dfa41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_full = model.transform(scaled_BMI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1f4ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Evaluate the model\n",
    "evaluator = BinaryClassificationEvaluator(labelCol=\"CUA_ANY\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d817bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Run Feature importance\n",
    "\n",
    "feature_dict= {0: 'AIAN', 1:'NHPI', 2:'Asian', 3:'Black', 4:'White', 5:'Hisp_Latino',\n",
    "        6:'Other', 7:'Mixed', 8:'Unknown', 9:'urbn', 10:'rural', 11:'no_urban', 12:'Metropol',\n",
    "        13:'Non_metro', 14:'no_metro', 15:'dead', 16:'R0', 17:'R1', 18:'R2', 19:'R3', 20:'R4', \n",
    "        21:'R5', 22:'R6', 23:'R7', 24:'R8',25:'R9', 26:'RU', 27:'endo', 28:'infertility', 29:'RA', \n",
    "        30:'dysmen', 31:'Irregular', 32:'spinal', 33:'scoliosis',34:'hearing_loss', 35:'mc', \n",
    "        36:'EOM', 37:'hemato', 38:'HPV', 39:'HIV', 40:'STI', 41:'smoker', 42:'AA', 43:'CVD',\n",
    "        44:'meno', 45:'preg', 46:'ectop', 47:'lynch', 48:'PCOS',49:'Db2', 50:'csect', 51:'ccsect', \n",
    "        52:'lcsect', 53:'MCCLD', 54:'HRP', 55:'MENA', 56:'API_ethn', 57:'PPROM', 58:'FT_loss',\n",
    "        59:'SA', 60:'scaled_BMI', 61:'scaled_age', 62:'age_log', 63:'age_exp'}\n",
    "\n",
    "# Optional: Print feature importance with actual feature names\n",
    "feature_importance = model.stages[-1].featureImportances\n",
    "print(\"Original Feature Importance (minus previous zeros):\")\n",
    "for i, imp in enumerate(feature_importance.toArray()):\n",
    "    feature_name = feature_dict.get(i, f\"Feature {i + 1}\")\n",
    "    print(f\"{feature_name}: {imp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d07bfc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Obtain Rank of features by importance\n",
    "\n",
    "feature_dict= {0: 'AIAN', 1:'NHPI', 2:'Asian', 3:'Black', 4:'White', 5:'Hisp_Latino',\n",
    "        6:'Other', 7:'Mixed', 8:'Unknown', 9:'urbn', 10:'rural', 11:'no_urban', 12:'Metropol',\n",
    "        13:'Non_metro', 14:'no_metro', 15:'dead', 16:'R0', 17:'R1', 18:'R2', 19:'R3', 20:'R4', \n",
    "        21:'R5', 22:'R6', 23:'R7', 24:'R8',25:'R9', 26:'RU', 27:'endo', 28:'infertility', 29:'RA', \n",
    "        30:'dysmen', 31:'Irregular', 32:'spinal', 33:'scoliosis',34:'hearing_loss', 35:'mc', \n",
    "        36:'EOM', 37:'hemato', 38:'HPV', 39:'HIV', 40:'STI', 41:'smoker', 42:'AA', 43:'CVD',\n",
    "        44:'meno', 45:'preg', 46:'ectop', 47:'lynch', 48:'PCOS',49:'Db2', 50:'csect', 51:'ccsect', \n",
    "        52:'lcsect', 53:'MCCLD', 54:'HRP', 55:'MENA', 56:'API_ethn', 57:'PPROM', 58:'FT_loss',\n",
    "        59:'SA', 60:'scaled_BMI', 61:'scaled_age', 62:'age_log', 63:'age_exp'}\n",
    "\n",
    "# Optional: Print feature importance with actual feature names and rank\n",
    "feature_importance = model.stages[-1].featureImportances\n",
    "print(\"Ranked Feature Importance:\")\n",
    "# Filter out features with zero importance\n",
    "non_zero_importance = [(i, imp) for i, imp in enumerate(feature_importance.toArray()) if imp > 0]\n",
    "# Sort features by importance in descending order\n",
    "sorted_features = sorted(non_zero_importance, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "for rank, (i, imp) in enumerate(sorted_features):\n",
    "    feature_name = feature_dict.get(i, f\"Feature {i + 1}\")\n",
    "    print(f\"Rank {rank + 1}: {feature_name} - Importance: {imp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb5108c",
   "metadata": {},
   "source": [
    "## Second run with df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40dccf33",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Define the Random Forest model; 500 trees selected based off of article\n",
    "rf = RandomForestClassifier(labelCol=\"CUA_ANY\", featuresCol=\"features\", numTrees=500)\n",
    "\n",
    "\n",
    "pipeline = Pipeline(stages=[assembler, rf])\n",
    "\n",
    "(training_data, testing_data) = random_non_cua2.randomSplit([0.8, 0.2], seed=1234)\n",
    "\n",
    "# Train the model\n",
    "model = pipeline.fit(random_non_cua2)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "predictions = model.transform(testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b708a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Evaluate the model\n",
    "evaluator = BinaryClassificationEvaluator(labelCol=\"CUA_ANY\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b60062",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Feature importance\n",
    "\n",
    "feature_dict= {0: 'AIAN', 1:'NHPI', 2:'Asian', 3:'Black', 4:'White', 5:'Hisp_Latino',\n",
    "        6:'Other', 7:'Mixed', 8:'Unknown', 9:'urbn', 10:'rural', 11:'no_urban', 12:'Metropol',\n",
    "        13:'Non_metro', 14:'no_metro', 15:'dead', 16:'R0', 17:'R1', 18:'R2', 19:'R3', 20:'R4', \n",
    "        21:'R5', 22:'R6', 23:'R7', 24:'R8',25:'R9', 26:'RU', 27:'endo', 28:'infertility', 29:'RA', \n",
    "        30:'dysmen', 31:'Irregular', 32:'spinal', 33:'scoliosis',34:'hearing_loss', 35:'mc', \n",
    "        36:'EOM', 37:'hemato', 38:'HPV', 39:'HIV', 40:'STI', 41:'smoker', 42:'AA', 43:'CVD',\n",
    "        44:'meno', 45:'preg', 46:'ectop', 47:'lynch', 48:'PCOS',49:'Db2', 50:'csect', 51:'ccsect', \n",
    "        52:'lcsect', 53:'MCCLD', 54:'HRP', 55:'MENA', 56:'API_ethn', 57:'PPROM', 58:'FT_loss',\n",
    "        59:'SA', 60:'scaled_BMI', 61:'scaled_age', 62:'age_log', 63:'age_exp'}\n",
    "\n",
    "# Optional: Print feature importance with actual feature names\n",
    "feature_importance = model.stages[-1].featureImportances\n",
    "print(\"Original Feature Importance (minus previous zeros):\")\n",
    "for i, imp in enumerate(feature_importance.toArray()):\n",
    "    feature_name = feature_dict.get(i, f\"Feature {i + 1}\")\n",
    "    print(f\"{feature_name}: {imp}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6765aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Ranked feature importance\n",
    "feature_dict= {0: 'AIAN', 1:'NHPI', 2:'Asian', 3:'Black', 4:'White', 5:'Hisp_Latino',\n",
    "        6:'Other', 7:'Mixed', 8:'Unknown', 9:'urbn', 10:'rural', 11:'no_urban', 12:'Metropol',\n",
    "        13:'Non_metro', 14:'no_metro', 15:'dead', 16:'R0', 17:'R1', 18:'R2', 19:'R3', 20:'R4', \n",
    "        21:'R5', 22:'R6', 23:'R7', 24:'R8',25:'R9', 26:'RU', 27:'endo', 28:'infertility', 29:'RA', \n",
    "        30:'dysmen', 31:'Irregular', 32:'spinal', 33:'scoliosis',34:'hearing_loss', 35:'mc', \n",
    "        36:'EOM', 37:'hemato', 38:'HPV', 39:'HIV', 40:'STI', 41:'smoker', 42:'AA', 43:'CVD',\n",
    "        44:'meno', 45:'preg', 46:'ectop', 47:'lynch', 48:'PCOS',49:'Db2', 50:'csect', 51:'ccsect', \n",
    "        52:'lcsect', 53:'MCCLD', 54:'HRP', 55:'MENA', 56:'API_ethn', 57:'PPROM', 58:'FT_loss',\n",
    "        59:'SA', 60:'scaled_BMI', 61:'scaled_age', 62:'age_log', 63:'age_exp'}\n",
    "\n",
    "# Optional: Print feature importance with actual feature names and rank\n",
    "feature_importance = model.stages[-1].featureImportances\n",
    "print(\"Ranked Feature Importance:\")\n",
    "# Filter out features with zero importance\n",
    "non_zero_importance = [(i, imp) for i, imp in enumerate(feature_importance.toArray()) if imp > 0]\n",
    "# Sort features by importance in descending order\n",
    "sorted_features = sorted(non_zero_importance, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "for rank, (i, imp) in enumerate(sorted_features):\n",
    "    feature_name = feature_dict.get(i, f\"Feature {i + 1}\")\n",
    "    print(f\"Rank {rank + 1}: {feature_name} - Importance: {imp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da24813b",
   "metadata": {},
   "source": [
    "## Third Run with df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038fd606",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Define the Random Forest model; 500 trees selected based off of article\n",
    "rf = RandomForestClassifier(labelCol=\"CUA_ANY\", featuresCol=\"features\", numTrees=500)\n",
    "\n",
    "pipeline = Pipeline(stages=[assembler, rf])\n",
    "\n",
    "(training_data, testing_data) = random_non_cua3.randomSplit([0.8, 0.2], seed=1234)\n",
    "\n",
    "# Train the model\n",
    "model = pipeline.fit(random_non_cua3)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "predictions = model.transform(testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17dbb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Evaluate the model\n",
    "evaluator = BinaryClassificationEvaluator(labelCol=\"CUA_ANY\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983617b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Feature importance rank\n",
    "feature_dict= {0: 'AIAN', 1:'NHPI', 2:'Asian', 3:'Black', 4:'White', 5:'Hisp_Latino',\n",
    "        6:'Other', 7:'Mixed', 8:'Unknown', 9:'urbn', 10:'rural', 11:'no_urban', 12:'Metropol',\n",
    "        13:'Non_metro', 14:'no_metro', 15:'dead', 16:'R0', 17:'R1', 18:'R2', 19:'R3', 20:'R4', \n",
    "        21:'R5', 22:'R6', 23:'R7', 24:'R8',25:'R9', 26:'RU', 27:'endo', 28:'infertility', 29:'RA', \n",
    "        30:'dysmen', 31:'Irregular', 32:'spinal', 33:'scoliosis',34:'hearing_loss', 35:'mc', \n",
    "        36:'EOM', 37:'hemato', 38:'HPV', 39:'HIV', 40:'STI', 41:'smoker', 42:'AA', 43:'CVD',\n",
    "        44:'meno', 45:'preg', 46:'ectop', 47:'lynch', 48:'PCOS',49:'Db2', 50:'csect', 51:'ccsect', \n",
    "        52:'lcsect', 53:'MCCLD', 54:'HRP', 55:'MENA', 56:'API_ethn', 57:'PPROM', 58:'FT_loss',\n",
    "        59:'SA', 60:'scaled_BMI', 61:'scaled_age', 62:'age_log', 63:'age_exp'}\n",
    "\n",
    "# Optional: Print feature importance with actual feature names and rank\n",
    "feature_importance = model.stages[-1].featureImportances\n",
    "print(\"Ranked Feature Importance:\")\n",
    "# Filter out features with zero importance\n",
    "non_zero_importance = [(i, imp) for i, imp in enumerate(feature_importance.toArray()) if imp > 0]\n",
    "# Sort features by importance in descending order\n",
    "sorted_features = sorted(non_zero_importance, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "for rank, (i, imp) in enumerate(sorted_features):\n",
    "    feature_name = feature_dict.get(i, f\"Feature {i + 1}\")\n",
    "    print(f\"Rank {rank + 1}: {feature_name} - Importance: {imp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd03a4d8",
   "metadata": {},
   "source": [
    "## Fourth run with df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3593ccd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Random Forest model; 500 trees selected based off of article\n",
    "rf = RandomForestClassifier(labelCol=\"CUA_ANY\", featuresCol=\"features\", numTrees=500)\n",
    "\n",
    "##(this can be more complex when you need string indexer and one-hot encoder)\n",
    "pipeline = Pipeline(stages=[assembler, rf])\n",
    "\n",
    "(training_data, testing_data) = random_non_cua4.randomSplit([0.8, 0.2], seed=1234)\n",
    "\n",
    "# Train the model\n",
    "model = pipeline.fit(random_non_cua3)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "predictions = model.transform(testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac62871",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Evaluate the model\n",
    "evaluator = BinaryClassificationEvaluator(labelCol=\"CUA_ANY\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae851b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Feature importance rank\n",
    "\n",
    "feature_dict= {0: 'AIAN', 1:'NHPI', 2:'Asian', 3:'Black', 4:'White', 5:'Hisp_Latino',\n",
    "        6:'Other', 7:'Mixed', 8:'Unknown', 9:'urbn', 10:'rural', 11:'no_urban', 12:'Metropol',\n",
    "        13:'Non_metro', 14:'no_metro', 15:'dead', 16:'R0', 17:'R1', 18:'R2', 19:'R3', 20:'R4', \n",
    "        21:'R5', 22:'R6', 23:'R7', 24:'R8',25:'R9', 26:'RU', 27:'endo', 28:'infertility', 29:'RA', \n",
    "        30:'dysmen', 31:'Irregular', 32:'spinal', 33:'scoliosis',34:'hearing_loss', 35:'mc', \n",
    "        36:'EOM', 37:'hemato', 38:'HPV', 39:'HIV', 40:'STI', 41:'smoker', 42:'AA', 43:'CVD',\n",
    "        44:'meno', 45:'preg', 46:'ectop', 47:'lynch', 48:'PCOS',49:'Db2', 50:'csect', 51:'ccsect', \n",
    "        52:'lcsect', 53:'MCCLD', 54:'HRP', 55:'MENA', 56:'API_ethn', 57:'PPROM', 58:'FT_loss',\n",
    "        59:'SA', 60:'scaled_BMI', 61:'scaled_age', 62:'age_log', 63:'age_exp'}\n",
    "\n",
    "# Optional: Print feature importance with actual feature names and rank\n",
    "feature_importance = model.stages[-1].featureImportances\n",
    "print(\"Ranked Feature Importance:\")\n",
    "# Filter out features with zero importance\n",
    "non_zero_importance = [(i, imp) for i, imp in enumerate(feature_importance.toArray()) if imp > 0]\n",
    "# Sort features by importance in descending order\n",
    "sorted_features = sorted(non_zero_importance, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "for rank, (i, imp) in enumerate(sorted_features):\n",
    "    feature_name = feature_dict.get(i, f\"Feature {i + 1}\")\n",
    "    print(f\"Rank {rank + 1}: {feature_name} - Importance: {imp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21284110",
   "metadata": {},
   "source": [
    "## Fifth run with df5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ebb0da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Define the Random Forest model; 500 trees selected based off of article\n",
    "rf = RandomForestClassifier(labelCol=\"CUA_ANY\", featuresCol=\"features\", numTrees=500)\n",
    "\n",
    "\n",
    "pipeline = Pipeline(stages=[assembler, rf])\n",
    "\n",
    "(training_data, testing_data) = random_non_cua5.randomSplit([0.8, 0.2], seed=1234)\n",
    "\n",
    "# Train the model\n",
    "model = pipeline.fit(random_non_cua3)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "predictions = model.transform(testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec93aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Evaluate the model\n",
    "evaluator = BinaryClassificationEvaluator(labelCol=\"CUA_ANY\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fef2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Feature importance rank\n",
    "feature_dict= {0: 'AIAN', 1:'NHPI', 2:'Asian', 3:'Black', 4:'White', 5:'Hisp_Latino',\n",
    "        6:'Other', 7:'Mixed', 8:'Unknown', 9:'urbn', 10:'rural', 11:'no_urban', 12:'Metropol',\n",
    "        13:'Non_metro', 14:'no_metro', 15:'dead', 16:'R0', 17:'R1', 18:'R2', 19:'R3', 20:'R4', \n",
    "        21:'R5', 22:'R6', 23:'R7', 24:'R8',25:'R9', 26:'RU', 27:'endo', 28:'infertility', 29:'RA', \n",
    "        30:'dysmen', 31:'Irregular', 32:'spinal', 33:'scoliosis',34:'hearing_loss', 35:'mc', \n",
    "        36:'EOM', 37:'hemato', 38:'HPV', 39:'HIV', 40:'STI', 41:'smoker', 42:'AA', 43:'CVD',\n",
    "        44:'meno', 45:'preg', 46:'ectop', 47:'lynch', 48:'PCOS',49:'Db2', 50:'csect', 51:'ccsect', \n",
    "        52:'lcsect', 53:'MCCLD', 54:'HRP', 55:'MENA', 56:'API_ethn', 57:'PPROM', 58:'FT_loss',\n",
    "        59:'SA', 60:'scaled_BMI', 61:'scaled_age', 62:'age_log', 63:'age_exp'}\n",
    "\n",
    "# Optional: Print feature importance with actual feature names and rank\n",
    "feature_importance = model.stages[-1].featureImportances\n",
    "print(\"Ranked Feature Importance:\")\n",
    "# Filter out features with zero importance\n",
    "non_zero_importance = [(i, imp) for i, imp in enumerate(feature_importance.toArray()) if imp > 0]\n",
    "# Sort features by importance in descending order\n",
    "sorted_features = sorted(non_zero_importance, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "for rank, (i, imp) in enumerate(sorted_features):\n",
    "    feature_name = feature_dict.get(i, f\"Feature {i + 1}\")\n",
    "    print(f\"Rank {rank + 1}: {feature_name} - Importance: {imp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e168a95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
