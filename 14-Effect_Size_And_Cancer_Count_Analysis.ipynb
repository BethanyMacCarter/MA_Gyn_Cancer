{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8b4b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2aab5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set max columns, rows, column width in pandas so doesn't truncate\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth',250) # or -1\n",
    "pd.set_option('display.max_columns', None) # or 500\n",
    "pd.set_option('display.max_rows', None) # or 500\n",
    "\n",
    "# sets the cell width to 100% respective to the screen size\n",
    "from IPython.core.display import display, HTML\n",
    "from pyspark.sql.functions import when, col\n",
    "from pyspark.sql.functions import avg\n",
    "display(HTML(\"<style>.container { width:92% !important; }</style>\"))\n",
    "from pyspark.sql.functions import col, sum as spark_sum\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import expr\n",
    "from pyspark.sql.functions import stddev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93996a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql('use CUA_db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa7bedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#call in data frame with all features\n",
    "\n",
    "cua_non= spark.sql(\"\"\"\n",
    "    SELECT *\n",
    "    FROM cua_non_consolidated_cua_non\n",
    "\"\"\")\n",
    "cua_non"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc3d48f",
   "metadata": {},
   "source": [
    "## Obtain Means and Stdev for all features BEFORE matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a53c59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take means of all features\n",
    "means=cua_non.groupby('CUA_ANY').mean()\n",
    "\n",
    "means.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4632ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#obtain stdev for each feature\n",
    "\n",
    "from pyspark.sql.functions import col, stddev\n",
    "\n",
    "# Filter out the 'personid' column from the DataFrame\n",
    "numerical_columns1 = [col_name for col_name in cua_non.columns if col_name != 'personid']\n",
    "\n",
    "# Group by the 'CUA_ANY' column\n",
    "grouped_stdev1 = cua_non.groupBy('CUA_ANY')\n",
    "\n",
    "# Calculate standard deviation for each column\n",
    "stdev_matched1 = grouped_stdev1.agg(*(stddev(col(col_name)).alias(f'stddev_{col_name}') for col_name in numerical_columns1))\n",
    "\n",
    "stdev_matched1.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36eb869",
   "metadata": {},
   "source": [
    "## Obtain Means & Stdev for All Features After Matching\n",
    "\n",
    "### First need to isolate matched personids from the DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f201afcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#call in the saved DF with control and treatments matched by PS, should be 28,462 each\n",
    "matches= spark.sql(\"\"\"\n",
    "    SELECT *\n",
    "    FROM ps_matches_updated\n",
    "\"\"\")\n",
    "matches\n",
    "\n",
    "matches.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85a441c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Double check for nulls\n",
    "\n",
    "null_count = matches.filter(col('Control_PersonID').isNull()).count()\n",
    "\n",
    "# Print the count of null values\n",
    "print(\"Number of null or NaN values in column 'column_name':\", null_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed577644",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Obtain a list of all matched personids (control and treatment)\n",
    "\n",
    "all_personid_list = matches.select('Treatment_PersonID', 'Control_PersonID').collect()\n",
    "\n",
    "# Extract the 'personid' values from the collected rows\n",
    "all_personid_list = [row.asDict() for row in all_personid_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e47f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "personid_values = [d['Treatment_PersonID'] for d in all_personid_list] + [d['Control_PersonID'] for d in all_personid_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931aeec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "control_personids_list = matches.select('Control_PersonID').rdd.flatMap(lambda x: x).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea2bae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(control_personids_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38a6867",
   "metadata": {},
   "outputs": [],
   "source": [
    "personid_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632ef0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Double check for duplicates\n",
    "\n",
    "if len(personid_values) == len(set(personid_values)):\n",
    "    print(\"No duplicates\")\n",
    "else:\n",
    "    print(\"Duplicates found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aee64c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(personid_values)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d35a027",
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_set=cua_non.filter(col('personid').isin(personid_values))\n",
    "matched_set.count()\n",
    "\n",
    "#56924"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf57f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Obtain means for matched group\n",
    "means_matched=matched_set.groupby('CUA_ANY').mean()\n",
    "\n",
    "means_matched.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d57937",
   "metadata": {},
   "outputs": [],
   "source": [
    "#obtain stddev for matched\n",
    "\n",
    "from pyspark.sql.functions import col, stddev\n",
    "\n",
    "# Filter out the 'personid' column from the DataFrame\n",
    "numerical_columns = [col_name for col_name in matched_set.columns if col_name != 'personid']\n",
    "\n",
    "# Group by the 'CUA_ANY' column\n",
    "grouped_matched = matched_set.groupBy('CUA_ANY')\n",
    "\n",
    "# Calculate standard deviation for each column\n",
    "stdev_matched = grouped_matched.agg(*(stddev(col(col_name)).alias(f'stddev_{col_name}') for col_name in numerical_columns))\n",
    "\n",
    "stdev_matched.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf340a36",
   "metadata": {},
   "source": [
    "#### Means and Stdevs were extracted and used to calculate effect sizes in excel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbdd248b",
   "metadata": {},
   "source": [
    "## Obtain Cancer Counts for each Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bca329b",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_Any_Gyn = matched_set.filter(matched_set['Any_Gyn'] == 1)\n",
    "\n",
    "Any_Gyn_count=filter_Any_Gyn.groupby('CUA_ANY').count()\n",
    "Any_Gyn_count.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3de551e",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_utc = matched_set.filter(matched_set['UTC'] == 1)\n",
    "\n",
    "utc_count=filter_utc.groupby('CUA_ANY').count()\n",
    "utc_count.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95176d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_ovc = matched_set.filter(matched_set['OVC2'] == 1)\n",
    "\n",
    "ovc_count=filter_ovc.groupby('CUA_ANY').count()\n",
    "ovc_count.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e4b7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_OV_FT= matched_set.filter(matched_set['OV_FT'] == 1)\n",
    "\n",
    "OV_FT_count=filter_OV_FT.groupby('CUA_ANY').count()\n",
    "OV_FT_count.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780e8b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_cvxc = matched_set.filter(matched_set['CVX'] == 1)\n",
    "\n",
    "cvxc_count=filter_cvxc.groupby('CUA_ANY').count()\n",
    "cvxc_count.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79dbf327",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_breastc = matched_set.filter(matched_set['Breastc'] == 1)\n",
    "\n",
    "breastc_count=filter_breastc.groupby('CUA_ANY').count()\n",
    "breastc_count.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a4a5a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c3f000",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55e1018",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
