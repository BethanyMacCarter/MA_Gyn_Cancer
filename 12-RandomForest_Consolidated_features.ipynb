{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4787eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7ee1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set max columns, rows, column width in pandas so doesn't truncate\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth',250) # or -1\n",
    "pd.set_option('display.max_columns', None) # or 500\n",
    "pd.set_option('display.max_rows', None) # or 500\n",
    "\n",
    "# sets the cell width to 100% respective to the screen size\n",
    "from IPython.core.display import display, HTML\n",
    "from pyspark.sql.functions import when, col\n",
    "from pyspark.sql.functions import avg\n",
    "display(HTML(\"<style>.container { width:92% !important; }</style>\"))\n",
    "from pyspark.sql.functions import col, sum as spark_sum\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c3586f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, max\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import rank\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c4fab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer, OneHotEncoder\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.sql.functions import col, sum as spark_sum\n",
    "import matplotlib.pyplot as plt\n",
    "from pyspark.sql.functions import col, log, exp\n",
    "from pyspark.sql.functions import rand\n",
    "from pyspark.sql import Window\n",
    "from pyspark.sql.functions import row_number\n",
    "from pyspark.sql.functions import col, udf\n",
    "from pyspark.sql.types import DoubleType\n",
    "from pyspark.sql.functions import col, expr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eae5a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql('use CUA_db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d24362",
   "metadata": {},
   "outputs": [],
   "source": [
    "#call in dataframe--NOTE updated to include the table with consolidated features\n",
    "\n",
    "cua_non= spark.sql(\"\"\"\n",
    "    SELECT *\n",
    "    FROM consolidated_cua_non\n",
    "\"\"\")\n",
    "cua_non"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff69cd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cua_non.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e29901a",
   "metadata": {},
   "source": [
    "## Alter numerics in Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ee46db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Altering age columns\n",
    "##Chose scaled age based off of highest average feature importance\n",
    "\n",
    "# Dividing by 100\n",
    "scaled_divided = cua_non.withColumn(\"scaled_age\", col(\"age\") / 100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edeb4170",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Altering BMI columns\n",
    "\n",
    "# Dividing by 40 (although higher BMIs, this is a typical high range)\n",
    "scaled_BMI = scaled_exp.withColumn(\"scaled_BMI\", col(\"BMI\") / 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c21c029",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Drop features from the data frame that are no longer being used, pre previous feature analysis\n",
    "rdxn=scaled_BMI.drop('AIAN', 'NHPI', 'Asian', 'MENA', 'Other', 'API_ethn', \n",
    "                     'Mixed', 'Metropol', 'Non_metro', 'no_metro', 'R0', 'R1', 'R2', 'R3', 'R4',\n",
    "                    'R5', 'R6', 'R7', 'R8', 'R9', 'RU', 'PPROM', 'csect', 'ccsect', 'lsect', 'BMI')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59ab46c",
   "metadata": {},
   "source": [
    "## Create DF with equal groups to deal with imbalance classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab4c315",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_CUA = rdxn.filter(scaled_BMI['CUA_ANY'] == 1)  # Filter treatment group\n",
    "grouped_non=rdxn.filter(scaled_BMI['CUA_ANY'] == 0)  # Filter control group\n",
    "\n",
    "print(grouped_CUA.count())\n",
    "print(grouped_non.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00db60b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## order the grouped non and then randomize\n",
    "ordered_and_randomized_df = grouped_non.orderBy(rand())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8429458e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new column named '_index' as an index using row_number\n",
    "window_spec = Window.orderBy(\"personid\")  # Replace \"any_column\" with a column that defines the order\n",
    "df_with_index = ordered_and_randomized_df.withColumn(\"_index\", row_number().over(window_spec))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a917782",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the total number of rows in the original DataFrame\n",
    "total_rows = df_with_index.count()\n",
    "\n",
    "# Number of rows for each random DataFrame\n",
    "rows_per_dataframe = 28462\n",
    "\n",
    "start_index_df1 = 0\n",
    "end_index_df1 = rows_per_dataframe\n",
    "\n",
    "# Filter the original DataFrame for the first DataFrame\n",
    "df1 = df_with_index.filter((col(\"_index\") >= start_index_df1) & (col(\"_index\") < end_index_df1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12398cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc76bcda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the start and end indices for the second DataFrame\n",
    "start_index_df2 = end_index_df1\n",
    "end_index_df2 = start_index_df2 + rows_per_dataframe\n",
    "\n",
    "# Filter the original DataFrame for the second DataFrame\n",
    "df2 = df_with_index.filter((col(\"_index\") >= start_index_df2) & (col(\"_index\") < end_index_df2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbe7869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the start and end indices for the third DataFrame\n",
    "start_index_df3 = end_index_df2\n",
    "end_index_df3 = start_index_df3 + rows_per_dataframe\n",
    "\n",
    "# Filter the original DataFrame for the third DataFrame\n",
    "df3 = df_with_index.filter((col(\"_index\") >= start_index_df3) & (col(\"_index\") < end_index_df3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb858f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the start and end indices for the fourth DataFrame\n",
    "start_index_df4 = end_index_df3\n",
    "end_index_df4 = start_index_df4 + rows_per_dataframe\n",
    "\n",
    "# Filter the original DataFrame for the fourth DataFrame\n",
    "df4 = df_with_index.filter((col(\"_index\") >= start_index_df4) & (col(\"_index\") < end_index_df4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a471f1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the start and end indices for the fifth DataFrame\n",
    "start_index_df5 = end_index_df4\n",
    "end_index_df5 = start_index_df5 + rows_per_dataframe\n",
    "\n",
    "# Filter the original DataFrame for the fifth DataFrame\n",
    "df5 = df_with_index.filter((col(\"_index\") >= start_index_df5) & (col(\"_index\") < end_index_df5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75db336",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1a=df1.drop('_index')\n",
    "df2a=df2.drop('_index')\n",
    "df3a=df3.drop('_index')\n",
    "df4a=df4.drop('_index')\n",
    "df5a=df5.drop('_index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed7f6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Recombine with the CUA df\n",
    "random_non_cua1=grouped_CUA.union(df1a)\n",
    "random_non_cua2=grouped_CUA.union(df2a)\n",
    "random_non_cua3=grouped_CUA.union(df3a)\n",
    "random_non_cua4=grouped_CUA.union(df4a)\n",
    "random_non_cua5=grouped_CUA.union(df5a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be930aed",
   "metadata": {},
   "source": [
    "## RF Consolidated Rerun"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613ff450",
   "metadata": {},
   "source": [
    "## First run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feedb200",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chosen features based on previous feature analysis\n",
    "binary_cols= ['Black', 'White', 'Hisp_Latino',\n",
    "        'Other_plus', 'Unknown', 'urbn', 'rural', 'no_urban', 'dead','endo', 'infertility', \n",
    "        'RA', 'dysmen', 'Irregular', 'spinal', 'scoliosis',\n",
    "        'hearing_loss', 'mc', 'EOM', 'hemato', 'HPV', 'HIV', 'STI', 'smoker', 'AA', 'CVD',\n",
    "        'meno', 'preg', 'ectop', 'lynch', 'PCOS','Db2', 'any_csect', 'MCCLD', 'HRP',\n",
    "        'FT_loss']\n",
    "numerical_cols=['scaled_BMI', 'scaled_age']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505ede68",
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(\n",
    "    inputCols=binary_cols + numerical_cols, \n",
    "    outputCol=\"features\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d061e79",
   "metadata": {},
   "source": [
    "## First Run with df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ecd903f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the Random Forest model; 500 trees selected based off of article\n",
    "rf = RandomForestClassifier(labelCol=\"CUA_ANY\", featuresCol=\"features\", numTrees=500)\n",
    "\n",
    "##(this can be more complex when you need string indexer and one-hot encoder)\n",
    "pipeline = Pipeline(stages=[assembler, rf])\n",
    "\n",
    "(training_data, testing_data) = random_non_cua1.randomSplit([0.8, 0.2], seed=1234)\n",
    "\n",
    "# Train the model\n",
    "model = pipeline.fit(random_non_cua1)\n",
    "\n",
    "#Make predictions on the testing set\n",
    "predictions = model.transform(testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f50c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_full1 = model.transform(rdxn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579def97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "evaluator = BinaryClassificationEvaluator(labelCol=\"CUA_ANY\", metricName=\"areaUnderROC\")\n",
    "auc = evaluator.evaluate(predictions)\n",
    "\n",
    "print(f\"ROC AUC: {auc}\")\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator(labelCol=\"CUA_ANY\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "#ROC AUC: 0.8494792175389134\n",
    "#Accuracy: 0.7712779745960425"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9d580f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This analysis will print all of the features in order and their importance\n",
    "\n",
    "# Feature Importance\n",
    "feature_dict= {0:'Black', 1:'White', 2:'Hisp_Latino',\n",
    "        3:'Other_plus', 4:'Unknown', 5:'urbn', 6:'rural', 7:'no_urban', 8:'dead', 9:'endo', \n",
    "        10:'infertility', 11:'RA', 12:'dysmen', 13:'Irregular', 14:'spinal', 15:'scoliosis',\n",
    "        16:'hearing_loss', 17:'mc', 18:'EOM', 19:'hemato', 20:'HPV', 21:'HIV', 22:'STI', \n",
    "        23:'smoker', 24:'AA', 25:'CVD',26:'meno', 27:'preg', 28:'ectop', 29:'lynch', 30:'PCOS',\n",
    "        31:'Db2', 32:'any_csect', 33:'MCCLD', 34:'HRP', 35:'FT_loss',\n",
    "        36:'scaled_BMI', 37:'scaled_age'}\n",
    "\n",
    "\n",
    "# Optional: Print feature importance with actual feature names\n",
    "feature_importance = model.stages[-1].featureImportances\n",
    "print(\"Original Feature Importance (minus previous zeros):\")\n",
    "for i, imp in enumerate(feature_importance.toArray()):\n",
    "    feature_name = feature_dict.get(i, f\"Feature {i + 1}\")\n",
    "    print(f\"{feature_name}: {imp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0217d770",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This analysis will print all of the features in order of their rank, but will exclude feature importance =0\n",
    "\n",
    "feature_dict= feature_dict= {0:'Black', 1:'White', 2:'Hisp_Latino',\n",
    "        3:'Other_plus', 4:'Unknown', 5:'urbn', 6:'rural', 7:'no_urban', 8:'dead', 9:'endo', \n",
    "        10:'infertility', 11:'RA', 12:'dysmen', 13:'Irregular', 14:'spinal', 15:'scoliosis',\n",
    "        16:'hearing_loss', 17:'mc', 18:'EOM', 19:'hemato', 20:'HPV', 21:'HIV', 22:'STI', \n",
    "        23:'smoker', 24:'AA', 25:'CVD',26:'meno', 27:'preg', 28:'ectop', 29:'lynch', 30:'PCOS',\n",
    "        31:'Db2', 32:'any_csect', 33:'MCCLD', 34:'HRP', 35:'FT_loss',\n",
    "        36:'scaled_BMI', 37:'scaled_age'}\n",
    "\n",
    "\n",
    "# Optional: Print feature importance with actual feature names and rank\n",
    "feature_importance = model.stages[-1].featureImportances\n",
    "print(\"Ranked Feature Importance:\")\n",
    "# Filter out features with zero importance\n",
    "non_zero_importance = [(i, imp) for i, imp in enumerate(feature_importance.toArray()) if imp > 0]\n",
    "# Sort features by importance in descending order\n",
    "sorted_features = sorted(non_zero_importance, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "for rank, (i, imp) in enumerate(sorted_features):\n",
    "    feature_name = feature_dict.get(i, f\"Feature {i + 1}\")\n",
    "    print(f\"Rank {rank + 1}: {feature_name} - Importance: {imp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3c0789",
   "metadata": {},
   "source": [
    "## Second run with df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5b2658",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Define the Random Forest model; 500 trees selected based off of article\n",
    "rf = RandomForestClassifier(labelCol=\"CUA_ANY\", featuresCol=\"features\", numTrees=500)\n",
    "\n",
    "\n",
    "pipeline = Pipeline(stages=[assembler, rf])\n",
    "\n",
    "(training_data, testing_data) = random_non_cua2.randomSplit([0.8, 0.2], seed=1234)\n",
    "\n",
    "# Train the model\n",
    "model = pipeline.fit(random_non_cua2)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "predictions = model.transform(testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b45fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_full2 = model.transform(rdxn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ed05cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Evaluate the model\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator(labelCol=\"CUA_ANY\", metricName=\"areaUnderROC\")\n",
    "auc = evaluator.evaluate(predictions)\n",
    "print(f\"ROC AUC: {auc}\")\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator(labelCol=\"CUA_ANY\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "#ROC AUC: 0.8485757413645247\n",
    "#Accuracy: 0.7718828307266914"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb681c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c261d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This analysis will print all of the features in order and their importance\n",
    "\n",
    "feature_dict= {0:'Black', 1:'White', 2:'Hisp_Latino',\n",
    "        3:'Other_plus', 4:'Unknown', 5:'urbn', 6:'rural', 7:'no_urban', 8:'dead', 9:'endo', \n",
    "        10:'infertility', 11:'RA', 12:'dysmen', 13:'Irregular', 14:'spinal', 15:'scoliosis',\n",
    "        16:'hearing_loss', 17:'mc', 18:'EOM', 19:'hemato', 20:'HPV', 21:'HIV', 22:'STI', \n",
    "        23:'smoker', 24:'AA', 25:'CVD',26:'meno', 27:'preg', 28:'ectop', 29:'lynch', 30:'PCOS',\n",
    "        31:'Db2', 32:'any_csect', 33:'MCCLD', 34:'HRP', 35:'FT_loss',\n",
    "        36:'scaled_BMI', 37:'scaled_age'}\n",
    "\n",
    "\n",
    "# Optional: Print feature importance with actual feature names\n",
    "feature_importance = model.stages[-1].featureImportances\n",
    "print(\"Original Feature Importance (minus previous zeros):\")\n",
    "for i, imp in enumerate(feature_importance.toArray()):\n",
    "    feature_name = feature_dict.get(i, f\"Feature {i + 1}\")\n",
    "    print(f\"{feature_name}: {imp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480d10f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This analysis will print all of the features in rank order, excluding zeros\n",
    "\n",
    "feature_dict= {0:'Black', 1:'White', 2:'Hisp_Latino',\n",
    "        3:'Other_plus', 4:'Unknown', 5:'urbn', 6:'rural', 7:'no_urban', 8:'dead', 9:'endo', \n",
    "        10:'infertility', 11:'RA', 12:'dysmen', 13:'Irregular', 14:'spinal', 15:'scoliosis',\n",
    "        16:'hearing_loss', 17:'mc', 18:'EOM', 19:'hemato', 20:'HPV', 21:'HIV', 22:'STI', \n",
    "        23:'smoker', 24:'AA', 25:'CVD',26:'meno', 27:'preg', 28:'ectop', 29:'lynch', 30:'PCOS',\n",
    "        31:'Db2', 32:'any_csect', 33:'MCCLD', 34:'HRP', 35:'FT_loss',\n",
    "        36:'scaled_BMI', 37:'scaled_age'}\n",
    "\n",
    "\n",
    "# Optional: Print feature importance with actual feature names and rank\n",
    "feature_importance = model.stages[-1].featureImportances\n",
    "print(\"Ranked Feature Importance:\")\n",
    "# Filter out features with zero importance\n",
    "non_zero_importance = [(i, imp) for i, imp in enumerate(feature_importance.toArray()) if imp > 0]\n",
    "# Sort features by importance in descending order\n",
    "sorted_features = sorted(non_zero_importance, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "for rank, (i, imp) in enumerate(sorted_features):\n",
    "    feature_name = feature_dict.get(i, f\"Feature {i + 1}\")\n",
    "    print(f\"Rank {rank + 1}: {feature_name} - Importance: {imp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d5cb22",
   "metadata": {},
   "source": [
    "## Third Run with df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e34ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Define the Random Forest model; 500 trees selected based off of article\n",
    "rf = RandomForestClassifier(labelCol=\"CUA_ANY\", featuresCol=\"features\", numTrees=500)\n",
    "\n",
    "pipeline = Pipeline(stages=[assembler, rf])\n",
    "\n",
    "(training_data, testing_data) = random_non_cua3.randomSplit([0.8, 0.2], seed=1234)\n",
    "\n",
    "# Train the model\n",
    "model = pipeline.fit(random_non_cua3)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "predictions = model.transform(testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71093a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_full3 = model.transform(rdxn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c4f3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Evaluate the model\n",
    "\n",
    "# Evaluate the model--UPDATE with AUROC\n",
    "evaluator = BinaryClassificationEvaluator(labelCol=\"CUA_ANY\", metricName=\"areaUnderROC\")\n",
    "auc = evaluator.evaluate(predictions)\n",
    "print(f\"ROC AUC: {auc}\")\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator(labelCol=\"CUA_ANY\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "#ROC AUC: 0.8464912972426755\n",
    "#Accuracy: 0.7700682623347447"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5eb9a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This analysis will print all of the features in order and their importance\n",
    "\n",
    "feature_dict= {0:'Black', 1:'White', 2:'Hisp_Latino',\n",
    "        3:'Other_plus', 4:'Unknown', 5:'urbn', 6:'rural', 7:'no_urban', 8:'dead', 9:'endo', \n",
    "        10:'infertility', 11:'RA', 12:'dysmen', 13:'Irregular', 14:'spinal', 15:'scoliosis',\n",
    "        16:'hearing_loss', 17:'mc', 18:'EOM', 19:'hemato', 20:'HPV', 21:'HIV', 22:'STI', \n",
    "        23:'smoker', 24:'AA', 25:'CVD',26:'meno', 27:'preg', 28:'ectop', 29:'lynch', 30:'PCOS',\n",
    "        31:'Db2', 32:'any_csect', 33:'MCCLD', 34:'HRP', 35:'FT_loss',\n",
    "        36:'scaled_BMI', 37:'scaled_age'}\n",
    "\n",
    "\n",
    "# Optional: Print feature importance with actual feature names\n",
    "feature_importance = model.stages[-1].featureImportances\n",
    "print(\"Original Feature Importance (minus previous zeros):\")\n",
    "for i, imp in enumerate(feature_importance.toArray()):\n",
    "    feature_name = feature_dict.get(i, f\"Feature {i + 1}\")\n",
    "    print(f\"{feature_name}: {imp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067b59e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This analysis will print all of the features in rank order, excluding zeros\n",
    "\n",
    "feature_dict= {0:'Black', 1:'White', 2:'Hisp_Latino',\n",
    "        3:'Other_plus', 4:'Unknown', 5:'urbn', 6:'rural', 7:'no_urban', 8:'dead', 9:'endo', \n",
    "        10:'infertility', 11:'RA', 12:'dysmen', 13:'Irregular', 14:'spinal', 15:'scoliosis',\n",
    "        16:'hearing_loss', 17:'mc', 18:'EOM', 19:'hemato', 20:'HPV', 21:'HIV', 22:'STI', \n",
    "        23:'smoker', 24:'AA', 25:'CVD',26:'meno', 27:'preg', 28:'ectop', 29:'lynch', 30:'PCOS',\n",
    "        31:'Db2', 32:'any_csect', 33:'MCCLD', 34:'HRP', 35:'FT_loss',\n",
    "        36:'scaled_BMI', 37:'scaled_age'}\n",
    "\n",
    "# Optional: Print feature importance with actual feature names and rank\n",
    "feature_importance = model.stages[-1].featureImportances\n",
    "print(\"Ranked Feature Importance:\")\n",
    "# Filter out features with zero importance\n",
    "non_zero_importance = [(i, imp) for i, imp in enumerate(feature_importance.toArray()) if imp > 0]\n",
    "# Sort features by importance in descending order\n",
    "sorted_features = sorted(non_zero_importance, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "for rank, (i, imp) in enumerate(sorted_features):\n",
    "    feature_name = feature_dict.get(i, f\"Feature {i + 1}\")\n",
    "    print(f\"Rank {rank + 1}: {feature_name} - Importance: {imp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ac04ef",
   "metadata": {},
   "source": [
    "## Fourth run with df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71fa04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Random Forest model; 500 trees selected based off of article\n",
    "rf = RandomForestClassifier(labelCol=\"CUA_ANY\", featuresCol=\"features\", numTrees=500)\n",
    "\n",
    "##(this can be more complex when you need string indexer and one-hot encoder)\n",
    "pipeline = Pipeline(stages=[assembler, rf])\n",
    "\n",
    "(training_data, testing_data) = random_non_cua4.randomSplit([0.8, 0.2], seed=1234)\n",
    "\n",
    "# Train the model\n",
    "model = pipeline.fit(random_non_cua3)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "predictions = model.transform(testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b550ca13",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Evaluate the model\n",
    "\n",
    "# Evaluate the model--UPDATE with AUROC\n",
    "evaluator = BinaryClassificationEvaluator(labelCol=\"CUA_ANY\", metricName=\"areaUnderROC\")\n",
    "auc = evaluator.evaluate(predictions)\n",
    "print(f\"ROC AUC: {auc}\")\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator(labelCol=\"CUA_ANY\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "#ROC AUC: 0.8424340329770147\n",
    "#Accuracy: 0.765056597252225"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35865ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_full4 = model.transform(rdxn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40963d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This analysis will print all of the features in order and their importance\n",
    "\n",
    "feature_dict= {0:'Black', 1:'White', 2:'Hisp_Latino',\n",
    "        3:'Other_plus', 4:'Unknown', 5:'urbn', 6:'rural', 7:'no_urban', 8:'dead', 9:'endo', \n",
    "        10:'infertility', 11:'RA', 12:'dysmen', 13:'Irregular', 14:'spinal', 15:'scoliosis',\n",
    "        16:'hearing_loss', 17:'mc', 18:'EOM', 19:'hemato', 20:'HPV', 21:'HIV', 22:'STI', \n",
    "        23:'smoker', 24:'AA', 25:'CVD',26:'meno', 27:'preg', 28:'ectop', 29:'lynch', 30:'PCOS',\n",
    "        31:'Db2', 32:'any_csect', 33:'MCCLD', 34:'HRP', 35:'FT_loss',\n",
    "        36:'scaled_BMI', 37:'scaled_age'}\n",
    "\n",
    "\n",
    "# Optional: Print feature importance with actual feature names\n",
    "feature_importance = model.stages[-1].featureImportances\n",
    "print(\"Original Feature Importance (minus previous zeros):\")\n",
    "for i, imp in enumerate(feature_importance.toArray()):\n",
    "    feature_name = feature_dict.get(i, f\"Feature {i + 1}\")\n",
    "    print(f\"{feature_name}: {imp}\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c21a223",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This analysis will print all of the features in rank order, excluding zeros\n",
    "\n",
    "\n",
    "feature_dict= {0:'Black', 1:'White', 2:'Hisp_Latino',\n",
    "        3:'Other_plus', 4:'Unknown', 5:'urbn', 6:'rural', 7:'no_urban', 8:'dead', 9:'endo', \n",
    "        10:'infertility', 11:'RA', 12:'dysmen', 13:'Irregular', 14:'spinal', 15:'scoliosis',\n",
    "        16:'hearing_loss', 17:'mc', 18:'EOM', 19:'hemato', 20:'HPV', 21:'HIV', 22:'STI', \n",
    "        23:'smoker', 24:'AA', 25:'CVD',26:'meno', 27:'preg', 28:'ectop', 29:'lynch', 30:'PCOS',\n",
    "        31:'Db2', 32:'any_csect', 33:'MCCLD', 34:'HRP', 35:'FT_loss',\n",
    "        36:'scaled_BMI', 37:'scaled_age'}\n",
    "\n",
    "# Optional: Print feature importance with actual feature names and rank\n",
    "feature_importance = model.stages[-1].featureImportances\n",
    "print(\"Ranked Feature Importance:\")\n",
    "# Filter out features with zero importance\n",
    "non_zero_importance = [(i, imp) for i, imp in enumerate(feature_importance.toArray()) if imp > 0]\n",
    "# Sort features by importance in descending order\n",
    "sorted_features = sorted(non_zero_importance, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "for rank, (i, imp) in enumerate(sorted_features):\n",
    "    feature_name = feature_dict.get(i, f\"Feature {i + 1}\")\n",
    "    print(f\"Rank {rank + 1}: {feature_name} - Importance: {imp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac403086",
   "metadata": {},
   "source": [
    "## Fifth run with df5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9803551",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Define the Random Forest model; 500 trees selected based off of article\n",
    "rf = RandomForestClassifier(labelCol=\"CUA_ANY\", featuresCol=\"features\", numTrees=500)\n",
    "\n",
    "\n",
    "pipeline = Pipeline(stages=[assembler, rf])\n",
    "\n",
    "(training_data, testing_data) = random_non_cua5.randomSplit([0.8, 0.2], seed=1234)\n",
    "\n",
    "# Train the model\n",
    "model = pipeline.fit(random_non_cua3)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "predictions = model.transform(testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a6706b",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Evaluate the model\n",
    "evaluator = BinaryClassificationEvaluator(labelCol=\"CUA_ANY\", metricName=\"areaUnderROC\")\n",
    "auc = evaluator.evaluate(predictions)\n",
    "print(f\"ROC AUC: {auc}\")\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator(labelCol=\"CUA_ANY\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "#ROC AUC: 0.8479994008089378\n",
    "#Accuracy: 0.7711915665773784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21441fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This analysis will print all of the features in order and their importance\n",
    "\n",
    "feature_dict= {0:'Black', 1:'White', 2:'Hisp_Latino',\n",
    "        3:'Other_plus', 4:'Unknown', 5:'urbn', 6:'rural', 7:'no_urban', 8:'dead', 9:'endo', \n",
    "        10:'infertility', 11:'RA', 12:'dysmen', 13:'Irregular', 14:'spinal', 15:'scoliosis',\n",
    "        16:'hearing_loss', 17:'mc', 18:'EOM', 19:'hemato', 20:'HPV', 21:'HIV', 22:'STI', \n",
    "        23:'smoker', 24:'AA', 25:'CVD',26:'meno', 27:'preg', 28:'ectop', 29:'lynch', 30:'PCOS',\n",
    "        31:'Db2', 32:'any_csect', 33:'MCCLD', 34:'HRP', 35:'FT_loss',\n",
    "        36:'scaled_BMI', 37:'scaled_age'}\n",
    "\n",
    "\n",
    "# Optional: Print feature importance with actual feature names\n",
    "feature_importance = model.stages[-1].featureImportances\n",
    "print(\"Original Feature Importance (minus previous zeros):\")\n",
    "for i, imp in enumerate(feature_importance.toArray()):\n",
    "    feature_name = feature_dict.get(i, f\"Feature {i + 1}\")\n",
    "    print(f\"{feature_name}: {imp}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba168848",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This analysis will print all of the features in rank order, excluding zeros\n",
    "\n",
    "feature_dict= {0:'Black', 1:'White', 2:'Hisp_Latino',\n",
    "        3:'Other_plus', 4:'Unknown', 5:'urbn', 6:'rural', 7:'no_urban', 8:'dead', 9:'endo', \n",
    "        10:'infertility', 11:'RA', 12:'dysmen', 13:'Irregular', 14:'spinal', 15:'scoliosis',\n",
    "        16:'hearing_loss', 17:'mc', 18:'EOM', 19:'hemato', 20:'HPV', 21:'HIV', 22:'STI', \n",
    "        23:'smoker', 24:'AA', 25:'CVD',26:'meno', 27:'preg', 28:'ectop', 29:'lynch', 30:'PCOS',\n",
    "        31:'Db2', 32:'any_csect', 33:'MCCLD', 34:'HRP', 35:'FT_loss',\n",
    "        36:'scaled_BMI', 37:'scaled_age'}\n",
    "\n",
    "# Optional: Print feature importance with actual feature names and rank\n",
    "feature_importance = model.stages[-1].featureImportances\n",
    "print(\"Ranked Feature Importance:\")\n",
    "# Filter out features with zero importance\n",
    "non_zero_importance = [(i, imp) for i, imp in enumerate(feature_importance.toArray()) if imp > 0]\n",
    "# Sort features by importance in descending order\n",
    "sorted_features = sorted(non_zero_importance, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "for rank, (i, imp) in enumerate(sorted_features):\n",
    "    feature_name = feature_dict.get(i, f\"Feature {i + 1}\")\n",
    "    print(f\"Rank {rank + 1}: {feature_name} - Importance: {imp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ab3189",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "96dbb4af",
   "metadata": {},
   "source": [
    "## Explore PSA distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593b2043",
   "metadata": {},
   "source": [
    "### First model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912dc561",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_CUA1 = predictions_full1.filter(predictions_full1['CUA_ANY'] == 1)  # Filter treatment group\n",
    "predictions_non1=predictions_full1.filter(predictions_full1['CUA_ANY'] == 0)  # Filter treatment group\n",
    "\n",
    "pred_sample_CUA1=predictions_CUA1.sample(fraction=0.1)\n",
    "pre_sample_non1=predictions_non1.sample(fraction=0.01)\n",
    "sample_concat1=pred_sample_CUA1.union(pre_sample_non1)\n",
    "sample_pdf1=sample_concat1.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36f9068",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_pdf1['prob'] = sample_pdf1['probability'].apply(lambda x: x[1])\n",
    "sample_pdf1.hist(column='prob', by='CUA_ANY', bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61fc8a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_description1 = sample_pdf1.groupby(\"CUA_ANY\")[\"prob\"].describe()\n",
    "print(grouped_description1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a54edfa",
   "metadata": {},
   "source": [
    "### Second model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628241cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_CUA2 = predictions_full2.filter(predictions_full2['CUA_ANY'] == 1)  # Filter treatment group\n",
    "predictions_non2=predictions_full2.filter(predictions_full2['CUA_ANY'] == 0)  # Filter treatment group\n",
    "\n",
    "pred_sample_CUA2=predictions_CUA2.sample(fraction=0.1)\n",
    "pre_sample_non2=predictions_non2.sample(fraction=0.01)\n",
    "sample_concat2=pred_sample_CUA2.union(pre_sample_non2)\n",
    "sample_pdf2=sample_concat2.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d0930e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_pdf2['prob'] = sample_pdf2['probability'].apply(lambda x: x[1])\n",
    "sample_pdf2.hist(column='prob', by='CUA_ANY', bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1acec06",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_description2 = sample_pdf2.groupby(\"CUA_ANY\")[\"prob\"].describe()\n",
    "print(grouped_description2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad8189a",
   "metadata": {},
   "source": [
    "#### Third model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab07c9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_CUA3 = predictions_full3.filter(predictions_full3['CUA_ANY'] == 1)  # Filter treatment group\n",
    "predictions_non3=predictions_full3.filter(predictions_full3['CUA_ANY'] == 0)  # Filter treatment group\n",
    "\n",
    "pred_sample_CUA3=predictions_CUA3.sample(fraction=0.1)\n",
    "pre_sample_non3=predictions_non3.sample(fraction=0.01)\n",
    "sample_concat3=pred_sample_CUA3.union(pre_sample_non3)\n",
    "sample_pdf3=sample_concat3.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79f088f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_pdf3['prob'] = sample_pdf3['probability'].apply(lambda x: x[1])\n",
    "sample_pdf3.hist(column='prob', by='CUA_ANY', bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75481fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_description3 = sample_pdf3.groupby(\"CUA_ANY\")[\"prob\"].describe()\n",
    "print(grouped_description3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d114bd96",
   "metadata": {},
   "source": [
    "#### Fourth model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba6b273",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_CUA4 = predictions_full4.filter(predictions_full4['CUA_ANY'] == 1)  # Filter treatment group\n",
    "predictions_non4=predictions_full4.filter(predictions_full4['CUA_ANY'] == 0)  # Filter treatment group\n",
    "\n",
    "pred_sample_CUA4=predictions_CUA4.sample(fraction=0.1)\n",
    "pre_sample_non4=predictions_non4.sample(fraction=0.01)\n",
    "sample_concat4=pred_sample_CUA4.union(pre_sample_non4)\n",
    "sample_pdf4=sample_concat4.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2862fd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_pdf4['prob'] = sample_pdf4['probability'].apply(lambda x: x[1])\n",
    "sample_pdf4.hist(column='prob', by='CUA_ANY', bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7664def3",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_description4 = sample_pdf4.groupby(\"CUA_ANY\")[\"prob\"].describe()\n",
    "print(grouped_description4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be650980",
   "metadata": {},
   "source": [
    "#### Fifth model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30482a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_CUA5 = predictions_full5.filter(predictions_full5['CUA_ANY'] == 1)  # Filter treatment group\n",
    "predictions_non5=predictions_full5.filter(predictions_full5['CUA_ANY'] == 0)  # Filter treatment group\n",
    "\n",
    "pred_sample_CUA5=predictions_CUA5.sample(fraction=0.1)\n",
    "pre_sample_non5=predictions_non5.sample(fraction=0.01)\n",
    "sample_concat5=pred_sample_CUA2.union(pre_sample_non5)\n",
    "sample_pdf5=sample_concat5.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7031b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_pdf5['prob'] = sample_pdf5['probability'].apply(lambda x: x[1])\n",
    "sample_pdf5.hist(column='prob', by='CUA_ANY', bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a4c0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_description5 = sample_pdf5.groupby(\"CUA_ANY\")[\"prob\"].describe()\n",
    "print(grouped_description5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faec6540",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6d9a1f49",
   "metadata": {},
   "source": [
    "## Save Full dataframe with PSA for matching\n",
    "#### Noted simlarities between all models and PSA distributions; Chose Model 1 due to highest AUC ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded5a2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a UDF to extract the first element from the vector\n",
    "extract_prob_udf = udf(lambda v: float(v[0]), DoubleType())\n",
    "\n",
    "# Create a new column 'prob0' using the UDF\n",
    "predictions_extracted = predictions_full1.withColumn('prob0', extract_prob_udf(col('probability')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2f154d",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_extracted.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96c2c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a UDF to extract the second element from the vector\n",
    "extract_prob_udf2 = udf(lambda v: float(v[1]), DoubleType())\n",
    "\n",
    "# Create a new column 'prob1' using the UDF\n",
    "predictions_extracted2 = predictions_extracted.withColumn('prob1', extract_prob_udf2(col('probability')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0e0422",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_extracted2.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e12218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of column names to select\n",
    "selected_columns = ['personid', 'CUA_ANY', 'age', 'prob0', 'prob1']\n",
    "\n",
    "# Select the specified columns\n",
    "simplified_probs = predictions_extracted2.select(*selected_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37835af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "simplified_probs.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed149cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the logit\n",
    "logit_df = simplified_probs.withColumn(\"logit_ps\", expr(\"1 / (1 + exp(-log(prob1)))\"))\n",
    "\n",
    "# Show the result\n",
    "logit_df.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1906f504",
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_df.write.saveAsTable('CUA_db.cua_non_age_PSM_update')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c4b1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "psm= spark.sql(\"\"\"\n",
    "    SELECT *\n",
    "    FROM cua_non_age_PSM\n",
    "\"\"\")\n",
    "psm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479cc2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "psm_CUA = logit_df.filter(logit_df['CUA_ANY'] == 1)  # Filter treatment group\n",
    "psm_non=logit_df.filter(logit_df['CUA_ANY'] == 0)  # Filter treatment group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d3d15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "psm_CUA.write.saveAsTable('CUA_db.psm_CUA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672a3dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "psm_non.write.saveAsTable('CUA_db.psm_non')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1301311",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
